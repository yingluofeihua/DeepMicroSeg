"""
ä¿®å¤åçš„SAMæ•°æ®é›† - è¡¥å……ç¼ºå¤±çš„æ–¹æ³•
åœ¨ lora/data_loaders.py ä¸­æ›¿æ¢æˆ–ä¿®æ”¹SAMDatasetç±»
"""

import torch
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as transforms
import numpy as np
from PIL import Image
from pathlib import Path
from typing import List, Tuple, Dict, Optional, Any
import random
import albumentations as A
from albumentations.pytorch import ToTensorV2
import cv2
import json
import datetime

from config.lora_config import DataConfig
from utils.file_utils import load_image, load_mask
from config.paths import DatasetPathValidator
from utils.data_splitter import DatasetSplitter, DataSplit, create_data_split, print_split_summary


class CellSegmentationDataset(Dataset):
    """ç»†èƒåˆ†å‰²æ•°æ®é›† - æ”¯æŒå±‚æ¬¡åŒ–æ•°æ®ç»“æ„å’Œæ•°æ®åˆ’åˆ†"""
    
    def __init__(
        self,
        data_dir: str = None,
        config: DataConfig = None,
        split: str = "train",
        transform: Optional[Any] = None,
        # ğŸ”§ æ–°å¢å‚æ•°ï¼šæ”¯æŒç›´æ¥ä¼ å…¥æ ·æœ¬åˆ—è¡¨
        samples: Optional[List[Dict]] = None
    ):
        self.data_dir = Path(data_dir) if data_dir else None
        self.config = config
        self.split = split
        self.transform = transform
        
        # ğŸ”§ ä¿®æ”¹ï¼šæ”¯æŒä»é¢„åˆ’åˆ†çš„æ ·æœ¬åŠ è½½æ•°æ®
        if samples is not None:
            # ç›´æ¥ä½¿ç”¨ä¼ å…¥çš„æ ·æœ¬åˆ—è¡¨
            self.samples = samples
            print(f"ä½¿ç”¨é¢„åˆ’åˆ†çš„{split}æ ·æœ¬: {len(self.samples)} ä¸ª")
        else:
            # ä¼ ç»Ÿæ–¹å¼ï¼šä»ç›®å½•ç»“æ„åŠ è½½æ•°æ®
            self.samples = self._load_samples()
        
        # åˆ›å»ºå¢å¼ºå˜æ¢
        if transform is None:
            self.transform = self._create_default_transforms()
        
        print(f"æ•°æ®é›† {split} åŠ è½½å®Œæˆ: {len(self.samples)} ä¸ªæ ·æœ¬")
    
    def _load_samples(self) -> List[Dict]:
        """åŠ è½½æ•°æ®æ ·æœ¬ - æ”¯æŒç»†èƒç±»å‹è¿‡æ»¤"""
        if self.data_dir is None:
            return []
            
        samples = []
        
        try:
            valid_datasets = DatasetPathValidator.validate_dataset_structure(self.data_dir)
            print(f"å‘ç° {len(valid_datasets)} ä¸ªæœ‰æ•ˆæ•°æ®é›†")
            
            for dataset_info in valid_datasets:
                # ğŸ”§ æ·»åŠ ç»†èƒç±»å‹è¿‡æ»¤
                if hasattr(self.config, '_cell_types_filter') and self.config._cell_types_filter:
                    if dataset_info['cell_type'] not in self.config._cell_types_filter:
                        continue  # è·³è¿‡ä¸åŒ¹é…çš„ç»†èƒç±»å‹
                
                images_dir = Path(dataset_info['images_dir'])
                masks_dir = Path(dataset_info['masks_dir'])
                
                image_mask_pairs = self._get_image_mask_pairs(images_dir, masks_dir)
                
                for img_path, mask_path in image_mask_pairs:
                    samples.append({
                        'image_path': str(img_path),
                        'mask_path': str(mask_path),
                        'sample_id': img_path.stem,
                        'cell_type': dataset_info['cell_type'],
                        'date': dataset_info['date'],
                        'magnification': dataset_info['magnification'],
                        'dataset_id': dataset_info['dataset_id']
                    })
            
            # æ‰“å°è¿‡æ»¤åçš„ç»Ÿè®¡
            if hasattr(self.config, '_cell_types_filter') and self.config._cell_types_filter:
                print(f"è¿‡æ»¤åæ ·æœ¬æ•° ({self.config._cell_types_filter}): {len(samples)}")
            
            samples = self._split_samples(samples)
            
            valid_samples = []
            for sample in samples:
                if self._validate_sample(sample):
                    valid_samples.append(sample)
            
            return valid_samples
            
        except Exception as e:
            print(f"åŠ è½½æ•°æ®æ ·æœ¬å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return []
    
    def _get_image_mask_pairs(self, images_dir: Path, masks_dir: Path) -> List[Tuple[Path, Path]]:
        """è·å–å›¾åƒ-æ©ç å¯¹"""
        pairs = []
        
        # è·å–æ‰€æœ‰å›¾åƒæ–‡ä»¶
        image_files = []
        for ext in ['.jpg', '.jpeg', '.png', '.tif', '.tiff']:
            image_files.extend(list(images_dir.glob(f"*{ext}")))
            image_files.extend(list(images_dir.glob(f"*{ext.upper()}")))
        
        # ä¸ºæ¯ä¸ªå›¾åƒæ–‡ä»¶æŸ¥æ‰¾å¯¹åº”çš„æ©ç 
        for img_file in image_files:
            mask_file = DatasetPathValidator.find_matching_mask(img_file, masks_dir)
            if mask_file:
                pairs.append((img_file, mask_file))
        
        return pairs
    
    def _split_samples(self, samples: List[Dict]) -> List[Dict]:
        """æ ¹æ®splitå‚æ•°åˆ†å‰²æ•°æ® - ä¿ç•™åŸæœ‰é€»è¾‘ä½œä¸ºåå¤‡"""
        if not samples:
            return []
        
        # æŒ‰æ•°æ®é›†åˆ†ç»„
        dataset_groups = {}
        for sample in samples:
            dataset_id = sample['dataset_id']
            if dataset_id not in dataset_groups:
                dataset_groups[dataset_id] = []
            dataset_groups[dataset_id].append(sample)
        
        # ä¸ºæ¯ä¸ªæ•°æ®é›†è¿›è¡Œåˆ†å‰²
        split_samples = []
        for dataset_id, dataset_samples in dataset_groups.items():
            n_total = len(dataset_samples)
            n_train = int(n_total * self.config.train_split_ratio)
            n_val = int(n_total * self.config.val_split_ratio)
            
            # éšæœºæ‰“ä¹±ï¼ˆä½¿ç”¨å›ºå®šç§å­ç¡®ä¿å¯é‡ç°ï¼‰
            random.seed(self.config.split_seed)
            random.shuffle(dataset_samples)
            
            if self.split == "train":
                split_samples.extend(dataset_samples[:n_train])
            elif self.split == "val":
                split_samples.extend(dataset_samples[n_train:n_train + n_val])
            elif self.split == "test":
                split_samples.extend(dataset_samples[n_train + n_val:])
            else:  # "all"
                split_samples.extend(dataset_samples)
        
        return split_samples
    
    def _validate_sample(self, sample: Dict) -> bool:
        """éªŒè¯æ ·æœ¬æœ‰æ•ˆæ€§"""
        img_path = Path(sample['image_path'])
        mask_path = Path(sample['mask_path'])
        
        if not (img_path.exists() and mask_path.exists()):
            return False
        
        try:
            # å°è¯•åŠ è½½å›¾åƒå’Œæ©ç 
            image = load_image(img_path, convert_to_grayscale=False)
            mask = load_mask(mask_path)
            
            if image is None or mask is None:
                return False
            
            # æ£€æŸ¥å°ºå¯¸åŒ¹é…
            if image.shape[:2] != mask.shape:
                return False
            
            # æ£€æŸ¥æ©ç æ˜¯å¦æœ‰å‰æ™¯å¯¹è±¡
            if self.config.filter_empty_images and np.max(mask) == 0:
                return False
            
            return True
            
        except Exception:
            return False
    
    def _create_default_transforms(self):
        """åˆ›å»ºé»˜è®¤çš„æ•°æ®å˜æ¢"""
        if self.split == "train" and self.config.use_data_augmentation:
            # è®­ç»ƒæ—¶ä½¿ç”¨æ•°æ®å¢å¼º
            transform = A.Compose([
                A.Resize(self.config.image_size[0], self.config.image_size[1]),
                A.OneOf([
                    A.HorizontalFlip(p=0.5),
                    A.VerticalFlip(p=0.5),
                    A.RandomRotate90(p=0.5),
                ], p=0.5),
                A.OneOf([
                    A.RandomBrightnessContrast(
                        brightness_limit=0.2, 
                        contrast_limit=0.2, 
                        p=0.5
                    ),
                    A.HueSaturationValue(
                        hue_shift_limit=10,
                        sat_shift_limit=20,
                        val_shift_limit=20,
                        p=0.5
                    ),
                ], p=0.3),
                A.OneOf([
                    A.GaussianBlur(blur_limit=3, p=0.3),
                    A.GaussNoise(p=0.3),  # ç§»é™¤var_limitå‚æ•°
                ], p=0.2),
                A.Normalize(mean=self.config.normalize_mean, std=self.config.normalize_std),
                ToTensorV2()
            ])
        else:
            # éªŒè¯/æµ‹è¯•æ—¶åªåšåŸºæœ¬å˜æ¢
            transform = A.Compose([
                A.Resize(self.config.image_size[0], self.config.image_size[1]),
                A.Normalize(mean=self.config.normalize_mean, std=self.config.normalize_std),
                ToTensorV2()
            ])
        
        return transform
    
    def __len__(self) -> int:
        return len(self.samples)
    
    def __getitem__(self, idx: int) -> Dict[str, torch.Tensor]:
        sample = self.samples[idx]
        
        # åŠ è½½å›¾åƒå’Œæ©ç 
        image = load_image(sample['image_path'], convert_to_grayscale=False)
        mask = load_mask(sample['mask_path'])
        
        if image is None or mask is None:
            # è¿”å›ä¸€ä¸ªæœ‰æ•ˆçš„ç©ºæ ·æœ¬
            return self._get_empty_sample()
        
        # ç¡®ä¿å›¾åƒæ˜¯RGBæ ¼å¼
        if len(image.shape) == 2:
            image = np.stack([image] * 3, axis=-1)
        elif image.shape[-1] == 1:
            image = np.repeat(image, 3, axis=-1)
        
        # åº”ç”¨å˜æ¢
        if self.transform:
            transformed = self.transform(image=image, mask=mask)
            image = transformed['image']
            mask = transformed['mask']
        
        # å¤„ç†æ©ç æ ¼å¼
        if isinstance(mask, torch.Tensor):
            mask = mask.long()
        else:
            mask = torch.from_numpy(mask).long()
        
        # ç”Ÿæˆå®ä¾‹æ©ç å’Œè¾¹ç•Œæ¡†
        instance_masks, boxes = self._process_mask(mask)
        return {
            'image': image,
            'masks': instance_masks,
            'boxes': boxes,
            'labels': torch.ones(len(boxes), dtype=torch.long),  # æ‰€æœ‰å¯¹è±¡éƒ½æ˜¯ç»†èƒ
            'sample_id': sample['sample_id'],
            'cell_type': sample['cell_type'],
            'date': sample['date'],
            'magnification': sample['magnification'],
            'dataset_id': sample['dataset_id']
        }
    
    def _get_empty_sample(self) -> Dict[str, torch.Tensor]:
        """è·å–ç©ºæ ·æœ¬"""
        h, w = self.config.image_size
        return {
            'image': torch.zeros(3, h, w),
            'masks': torch.zeros(0, h, w),
            'boxes': torch.zeros(0, 4),
            'labels': torch.zeros(0, dtype=torch.long),
            'sample_id': 'empty',
            'cell_type': 'unknown',
            'date': 'unknown',
            'magnification': 'unknown',
            'dataset_id': 'unknown'
        }
    
    def _process_mask(self, mask: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:
        """å¤„ç†æ©ç ï¼Œæå–å®ä¾‹å’Œè¾¹ç•Œæ¡†"""
        # è·å–æ‰€æœ‰å®ä¾‹ID
        unique_ids = torch.unique(mask)
        unique_ids = unique_ids[unique_ids > 0]  # æ’é™¤èƒŒæ™¯
        
        if len(unique_ids) == 0:
            return torch.zeros(0, mask.shape[-2], mask.shape[-1]), torch.zeros(0, 4)
        
        # é™åˆ¶å®ä¾‹æ•°é‡
        if len(unique_ids) > self.config.max_objects_per_image:
            unique_ids = unique_ids[:self.config.max_objects_per_image]
        
        instance_masks = []
        boxes = []
        
        for instance_id in unique_ids:
            # åˆ›å»ºå•ä¸ªå®ä¾‹æ©ç 
            instance_mask = (mask == instance_id).float()
            
            # è¿‡æ»¤å¤ªå°çš„å¯¹è±¡
            if torch.sum(instance_mask) < self.config.min_object_size:
                continue
            
            # è¿‡æ»¤å¤ªå¤§çš„å¯¹è±¡
            if (self.config.max_object_size is not None and 
                torch.sum(instance_mask) > self.config.max_object_size):
                continue
            
            instance_masks.append(instance_mask)
            
            # è®¡ç®—è¾¹ç•Œæ¡†
            pos = torch.where(instance_mask)
            if len(pos[0]) > 0:
                xmin = torch.min(pos[1])
                xmax = torch.max(pos[1])
                ymin = torch.min(pos[0])
                ymax = torch.max(pos[0])
                
                boxes.append([xmin, ymin, xmax, ymax])
        
        if len(instance_masks) == 0:
            return torch.zeros(0, mask.shape[-2], mask.shape[-1]), torch.zeros(0, 4)
        
        instance_masks = torch.stack(instance_masks)
        boxes = torch.tensor(boxes, dtype=torch.float32)
        
        return instance_masks, boxes


class SAMDataset(CellSegmentationDataset):
    """ä¸“é—¨ä¸ºSAMæ¨¡å‹ä¼˜åŒ–çš„æ•°æ®é›† - ä¿®å¤å®Œæ•´ç‰ˆ"""
    
    def __init__(
        self,
        data_dir: str = None,
        config: DataConfig = None,
        split: str = "train",
        transform: Optional[Any] = None,
        samples: Optional[List[Dict]] = None
    ):
        self.data_dir = Path(data_dir) if data_dir else None
        self.config = config
        self.split = split
        self.transform = transform
        
        # æ”¯æŒä»é¢„åˆ’åˆ†çš„æ ·æœ¬åŠ è½½æ•°æ®
        if samples is not None:
            self.samples = samples
            print(f"ä½¿ç”¨é¢„åˆ’åˆ†çš„{split}æ ·æœ¬: {len(self.samples)} ä¸ª")
        else:
            self.samples = self._load_samples()
        
        # åˆ›å»ºå¢å¼ºå˜æ¢
        if transform is None:
            self.transform = self._create_default_transforms()
        
        print(f"SAMæ•°æ®é›† {split} åŠ è½½å®Œæˆ: {len(self.samples)} ä¸ªæ ·æœ¬")
    
    def _load_samples(self) -> List[Dict]:
        """åŠ è½½æ•°æ®æ ·æœ¬ - æ”¯æŒç»†èƒç±»å‹è¿‡æ»¤"""
        if self.data_dir is None:
            return []
            
        samples = []
        
        try:
            valid_datasets = DatasetPathValidator.validate_dataset_structure(self.data_dir)
            print(f"å‘ç° {len(valid_datasets)} ä¸ªæœ‰æ•ˆæ•°æ®é›†")
            
            for dataset_info in valid_datasets:
                # æ·»åŠ ç»†èƒç±»å‹è¿‡æ»¤
                if hasattr(self.config, '_cell_types_filter') and self.config._cell_types_filter:
                    if dataset_info['cell_type'] not in self.config._cell_types_filter:
                        continue
                
                images_dir = Path(dataset_info['images_dir'])
                masks_dir = Path(dataset_info['masks_dir'])
                
                image_mask_pairs = self._get_image_mask_pairs(images_dir, masks_dir)
                
                for img_path, mask_path in image_mask_pairs:
                    samples.append({
                        'image_path': str(img_path),
                        'mask_path': str(mask_path),
                        'sample_id': img_path.stem,
                        'cell_type': dataset_info['cell_type'],
                        'date': dataset_info['date'],
                        'magnification': dataset_info['magnification'],
                        'dataset_id': dataset_info['dataset_id']
                    })
            
            if hasattr(self.config, '_cell_types_filter') and self.config._cell_types_filter:
                print(f"è¿‡æ»¤åæ ·æœ¬æ•° ({self.config._cell_types_filter}): {len(samples)}")
            
            samples = self._split_samples(samples)
            
            valid_samples = []
            for sample in samples:
                if self._validate_sample(sample):
                    valid_samples.append(sample)
            
            return valid_samples
            
        except Exception as e:
            print(f"åŠ è½½æ•°æ®æ ·æœ¬å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return []
    
    def _get_image_mask_pairs(self, images_dir: Path, masks_dir: Path) -> List[Tuple[Path, Path]]:
        """è·å–å›¾åƒ-æ©ç å¯¹"""
        pairs = []
        
        # è·å–æ‰€æœ‰å›¾åƒæ–‡ä»¶
        image_files = []
        for ext in ['.jpg', '.jpeg', '.png', '.tif', '.tiff']:
            image_files.extend(list(images_dir.glob(f"*{ext}")))
            image_files.extend(list(images_dir.glob(f"*{ext.upper()}")))
        
        # ä¸ºæ¯ä¸ªå›¾åƒæ–‡ä»¶æŸ¥æ‰¾å¯¹åº”çš„æ©ç 
        for img_file in image_files:
            mask_file = DatasetPathValidator.find_matching_mask(img_file, masks_dir)
            if mask_file:
                pairs.append((img_file, mask_file))
        
        return pairs
    
    def _split_samples(self, samples: List[Dict]) -> List[Dict]:
        """æ ¹æ®splitå‚æ•°åˆ†å‰²æ•°æ®"""
        if not samples:
            return []
        
        # æŒ‰æ•°æ®é›†åˆ†ç»„
        dataset_groups = {}
        for sample in samples:
            dataset_id = sample['dataset_id']
            if dataset_id not in dataset_groups:
                dataset_groups[dataset_id] = []
            dataset_groups[dataset_id].append(sample)
        
        # ä¸ºæ¯ä¸ªæ•°æ®é›†è¿›è¡Œåˆ†å‰²
        split_samples = []
        for dataset_id, dataset_samples in dataset_groups.items():
            n_total = len(dataset_samples)
            n_train = int(n_total * self.config.train_split_ratio)
            n_val = int(n_total * self.config.val_split_ratio)
            
            # éšæœºæ‰“ä¹±
            random.seed(self.config.split_seed)
            random.shuffle(dataset_samples)
            
            if self.split == "train":
                split_samples.extend(dataset_samples[:n_train])
            elif self.split == "val":
                split_samples.extend(dataset_samples[n_train:n_train + n_val])
            elif self.split == "test":
                split_samples.extend(dataset_samples[n_train + n_val:])
            else:  # "all"
                split_samples.extend(dataset_samples)
        
        return split_samples
    
    def _validate_sample(self, sample: Dict) -> bool:
        """éªŒè¯æ ·æœ¬æœ‰æ•ˆæ€§"""
        img_path = Path(sample['image_path'])
        mask_path = Path(sample['mask_path'])
        
        if not (img_path.exists() and mask_path.exists()):
            return False
        
        try:
            image = load_image(img_path, convert_to_grayscale=False)
            mask = load_mask(mask_path)
            
            if image is None or mask is None:
                return False
            
            if image.shape[:2] != mask.shape:
                return False
            
            if self.config.filter_empty_images and np.max(mask) == 0:
                return False
            
            return True
            
        except Exception:
            return False
    
    def _create_default_transforms(self):
        """åˆ›å»ºé»˜è®¤çš„æ•°æ®å˜æ¢"""
        if self.split == "train" and self.config.use_data_augmentation:
            # è®­ç»ƒæ—¶ä½¿ç”¨æ•°æ®å¢å¼º
            transform = A.Compose([
                A.Resize(self.config.image_size[0], self.config.image_size[1]),
                A.OneOf([
                    A.HorizontalFlip(p=0.5),
                    A.VerticalFlip(p=0.5),
                    A.RandomRotate90(p=0.5),
                ], p=0.5),
                A.OneOf([
                    A.RandomBrightnessContrast(
                        brightness_limit=0.2, 
                        contrast_limit=0.2, 
                        p=0.5
                    ),
                    A.HueSaturationValue(
                        hue_shift_limit=10,
                        sat_shift_limit=20,
                        val_shift_limit=20,
                        p=0.5
                    ),
                ], p=0.3),
                A.OneOf([
                    A.GaussianBlur(blur_limit=3, p=0.3),
                    A.GaussNoise(p=0.3),
                ], p=0.2),
                A.Normalize(mean=self.config.normalize_mean, std=self.config.normalize_std),
                ToTensorV2()
            ])
        else:
            # éªŒè¯/æµ‹è¯•æ—¶åªåšåŸºæœ¬å˜æ¢
            transform = A.Compose([
                A.Resize(self.config.image_size[0], self.config.image_size[1]),
                A.Normalize(mean=self.config.normalize_mean, std=self.config.normalize_std),
                ToTensorV2()
            ])
        
        return transform
    
    def __len__(self) -> int:
        return len(self.samples)
    
    def __getitem__(self, idx: int) -> Dict[str, Any]:
        """è·å–å•ä¸ªæ ·æœ¬ - ä¿®å¤ç‰ˆæœ¬"""
        try:
            sample = self.samples[idx]
            
            # åŠ è½½å›¾åƒå’Œæ©ç 
            image = load_image(sample['image_path'], convert_to_grayscale=False)
            mask = load_mask(sample['mask_path'])
            
            if image is None or mask is None:
                return self._get_empty_sample()
            
            # ç¡®ä¿å›¾åƒæ˜¯RGBæ ¼å¼
            if len(image.shape) == 2:
                image = np.stack([image] * 3, axis=-1)
            elif image.shape[-1] == 1:
                image = np.repeat(image, 3, axis=-1)
            
            # åº”ç”¨å˜æ¢
            if self.transform:
                transformed = self.transform(image=image, mask=mask)
                image = transformed['image']
                mask = transformed['mask']
            
            # ğŸ”§ å…³é”®ä¿®å¤ï¼šä¿æŒå¤šå®ä¾‹æ©ç ï¼Œä¸è¦åˆå¹¶ï¼
            instance_masks, boxes = self._process_mask_for_sam(mask)
            
            # ä¸ºSAMç”Ÿæˆç‚¹æç¤º
            point_prompts = self._generate_point_prompts_for_instances(instance_masks)
            
            return {
                'images': image,  # [3, H, W]
                'point_coords': point_prompts['coords'],
                'point_labels': point_prompts['labels'],
                'boxes': boxes,
                'mask_inputs': None,
                'multimask_output': True,  # å¯ç”¨å¤šæ©ç è¾“å‡º
                'ground_truth_masks': instance_masks,  # ğŸ¯ [N, H, W] - å¤šä¸ªäºŒè¿›åˆ¶æ©ç 
                'sample_id': sample['sample_id'],
                'cell_type': sample['cell_type'],
                'date': sample['date'],
                'magnification': sample['magnification'],
                'dataset_id': sample['dataset_id']
            }
            
        except Exception as e:
            print(f"åŠ è½½æ ·æœ¬å¤±è´¥ {idx}: {e}")
            return self._get_empty_sample()
    
    def _get_empty_sample(self) -> Dict[str, Any]:
        """è·å–ç©ºæ ·æœ¬"""
        h, w = self.config.image_size
        return {
            'images': torch.zeros(3, h, w),
            'point_coords': torch.zeros(0, 2),
            'point_labels': torch.zeros(0),
            'boxes': torch.zeros(0, 4),
            'mask_inputs': None,
            'multimask_output': True,
            'ground_truth_masks': torch.zeros(1, h, w),  # è‡³å°‘ä¸€ä¸ªç©ºæ©ç 
            'sample_id': 'empty',
            'cell_type': 'unknown',
            'date': 'unknown',
            'magnification': 'unknown',
            'dataset_id': 'unknown'
        }
    
    def _process_mask_for_sam(self, mask: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:
        """ä¸ºSAMå¤„ç†å¤šå®ä¾‹æ©ç  - ä¿æŒåˆ†ç¦»çŠ¶æ€"""
        # è·å–æ‰€æœ‰å®ä¾‹ID
        unique_ids = torch.unique(mask)
        unique_ids = unique_ids[unique_ids > 0]  # æ’é™¤èƒŒæ™¯
        
        if len(unique_ids) == 0:
            # æ²¡æœ‰å®ä¾‹ï¼Œè¿”å›ç©ºæ©ç 
            return torch.zeros(1, mask.shape[-2], mask.shape[-1]), torch.zeros(1, 4)
        
        # é™åˆ¶å®ä¾‹æ•°é‡
        if len(unique_ids) > self.config.max_objects_per_image:
            unique_ids = unique_ids[:self.config.max_objects_per_image]
        
        instance_masks = []
        boxes = []
        
        for instance_id in unique_ids:
            # ğŸ¯ å…³é”®ï¼šåˆ›å»ºå•ä¸ªå®ä¾‹çš„äºŒè¿›åˆ¶æ©ç 
            instance_mask = (mask == instance_id).float()
            
            # è¿‡æ»¤å¤ªå°çš„å¯¹è±¡
            if torch.sum(instance_mask) < self.config.min_object_size:
                continue
            
            # è¿‡æ»¤å¤ªå¤§çš„å¯¹è±¡
            if (self.config.max_object_size is not None and 
                torch.sum(instance_mask) > self.config.max_object_size):
                continue
            
            instance_masks.append(instance_mask)
            
            # è®¡ç®—è¾¹ç•Œæ¡†
            pos = torch.where(instance_mask)
            if len(pos[0]) > 0:
                xmin = torch.min(pos[1])
                xmax = torch.max(pos[1])
                ymin = torch.min(pos[0])
                ymax = torch.max(pos[0])
                boxes.append([xmin, ymin, xmax, ymax])
        
        if len(instance_masks) == 0:
            return torch.zeros(1, mask.shape[-2], mask.shape[-1]), torch.zeros(1, 4)
        
        # ğŸ¯ è¿”å›å¤šä¸ªäºŒè¿›åˆ¶æ©ç  [N, H, W]
        instance_masks = torch.stack(instance_masks)  # [N, H, W]
        boxes = torch.tensor(boxes, dtype=torch.float32)
        
        return instance_masks, boxes
    
    def _generate_point_prompts_for_instances(self, instance_masks: torch.Tensor) -> Dict[str, torch.Tensor]:
        """ä¸ºæ¯ä¸ªå®ä¾‹ç”Ÿæˆç‚¹æç¤º - ä¿®å¤ç‰ˆæœ¬"""
        all_coords = []
        all_labels = []
        
        for mask in instance_masks:
            # ä¸ºæ¯ä¸ªå®ä¾‹ç”Ÿæˆ1-2ä¸ªæ­£ä¾‹ç‚¹
            pos_coords = self._sample_points_from_mask(mask, num_points=1, positive=True)
            
            # å¯é€‰ï¼šæ·»åŠ è´Ÿä¾‹ç‚¹ï¼ˆåœ¨å…¶ä»–å®ä¾‹æˆ–èƒŒæ™¯åŒºåŸŸï¼‰
            neg_coords = self._sample_points_from_mask(mask, num_points=1, positive=False)
            
            if len(pos_coords) > 0:
                coords = torch.cat([pos_coords, neg_coords], dim=0) if len(neg_coords) > 0 else pos_coords
                labels = torch.cat([
                    torch.ones(len(pos_coords)), 
                    torch.zeros(len(neg_coords))
                ]) if len(neg_coords) > 0 else torch.ones(len(pos_coords))
                
                all_coords.append(coords)
                all_labels.append(labels)
        
        if len(all_coords) > 0:
            return {
                'coords': torch.cat(all_coords, dim=0),
                'labels': torch.cat(all_labels, dim=0)
            }
        else:
            return {
                'coords': torch.zeros(0, 2),
                'labels': torch.zeros(0)
            }
    
    def _sample_points_from_mask(self, mask: torch.Tensor, num_points: int, positive: bool) -> torch.Tensor:
        """ä»æ©ç ä¸­é‡‡æ ·ç‚¹ - ğŸ”§ æ–°å¢ç¼ºå¤±çš„æ–¹æ³•"""
        try:
            if positive:
                # ä»å‰æ™¯åŒºåŸŸé‡‡æ ·
                pos = torch.where(mask > 0.5)
            else:
                # ä»èƒŒæ™¯åŒºåŸŸé‡‡æ ·
                pos = torch.where(mask <= 0.5)
            
            if len(pos[0]) == 0:
                return torch.zeros(0, 2)
            
            # éšæœºé€‰æ‹©ç‚¹
            num_available = len(pos[0])
            num_to_sample = min(num_points, num_available)
            
            if num_to_sample == 0:
                return torch.zeros(0, 2)
            
            indices = torch.randperm(num_available)[:num_to_sample]
            
            coords = torch.stack([
                pos[1][indices],  # x coordinates
                pos[0][indices]   # y coordinates
            ], dim=1)
            
            return coords.float()
            
        except Exception as e:
            print(f"é‡‡æ ·ç‚¹å¤±è´¥: {e}")
            return torch.zeros(0, 2)


# ğŸ”§ ä¿®å¤collate_fnå‡½æ•°
def collate_fn_multi_instance(batch):
    """å¤šå®ä¾‹SAMçš„æ‰¹å¤„ç†å‡½æ•° - ä¿®å¤ç‰ˆæœ¬"""
    if len(batch) == 0:
        return {}
    
    images = []
    all_point_coords = []
    all_point_labels = []
    all_boxes = []
    all_masks = []
    sample_ids = []
    
    max_instances = 0
    
    # æ”¶é›†æ‰€æœ‰æ•°æ®ï¼Œæ‰¾åˆ°æœ€å¤§å®ä¾‹æ•°
    for item in batch:
        try:
            images.append(item['images'])
            
            if 'point_coords' in item and isinstance(item['point_coords'], torch.Tensor):
                all_point_coords.append(item['point_coords'])
            else:
                all_point_coords.append(torch.zeros(0, 2))
            
            if 'point_labels' in item and isinstance(item['point_labels'], torch.Tensor):
                all_point_labels.append(item['point_labels'])
            else:
                all_point_labels.append(torch.zeros(0))
            
            if 'boxes' in item and isinstance(item['boxes'], torch.Tensor):
                all_boxes.append(item['boxes'])
            else:
                all_boxes.append(torch.zeros(0, 4))
            
            # å¤„ç†å¤šå®ä¾‹æ©ç 
            if 'ground_truth_masks' in item:
                masks = item['ground_truth_masks']
                if isinstance(masks, torch.Tensor):
                    if len(masks.shape) == 2:
                        masks = masks.unsqueeze(0)  # [H, W] -> [1, H, W]
                    max_instances = max(max_instances, masks.shape[0])
                    all_masks.append(masks)
                else:
                    # å¤„ç†å¼‚å¸¸æƒ…å†µ
                    h, w = item['images'].shape[-2:]
                    default_mask = torch.zeros(1, h, w, dtype=torch.float32)
                    all_masks.append(default_mask)
                    max_instances = max(max_instances, 1)
            else:
                # å¦‚æœæ²¡æœ‰æ©ç ï¼Œåˆ›å»ºé»˜è®¤æ©ç 
                h, w = item['images'].shape[-2:]
                default_mask = torch.zeros(1, h, w, dtype=torch.float32)
                all_masks.append(default_mask)
                max_instances = max(max_instances, 1)
            
            sample_ids.append(item.get('sample_id', f'sample_{len(sample_ids)}'))
            
        except Exception as e:
            print(f"å¤„ç†æ‰¹æ¬¡é¡¹ç›®å¤±è´¥: {e}")
            continue
    
    if len(images) == 0:
        return {}
    
    # å †å å›¾åƒ
    try:
        images = torch.stack(images)
    except Exception as e:
        print(f"å †å å›¾åƒå¤±è´¥: {e}")
        return {}
    
    # ğŸ”§ å…³é”®ä¿®å¤ï¼šæ­£ç¡®å¤„ç†å¤šå®ä¾‹æ©ç 
    batch_size = len(all_masks)
    h, w = all_masks[0].shape[-2:]
    
    # åˆ›å»ºç»Ÿä¸€çš„æ©ç å¼ é‡ [B, max_instances, H, W]
    unified_masks = torch.zeros(batch_size, max_instances, h, w, dtype=torch.float32)
    
    for i, masks in enumerate(all_masks):
        try:
            num_instances = masks.shape[0]
            unified_masks[i, :num_instances] = masks
        except Exception as e:
            print(f"å¤„ç†æ©ç  {i} å¤±è´¥: {e}")
            continue
    
    return {
        'images': images,
        'point_coords': all_point_coords,
        'point_labels': all_point_labels,
        'boxes': all_boxes,
        'ground_truth_masks': unified_masks,  # [B, max_instances, H, W]
        'sample_ids': sample_ids
    }


# ğŸ”§ ä¿®å¤create_data_loaderså‡½æ•°
def create_data_loaders(config: DataConfig, dataset_type: str = "standard") -> Dict[str, DataLoader]:
    """åˆ›å»ºæ•°æ®åŠ è½½å™¨ - ä¿®å¤ç‰ˆæœ¬"""
    
    datasets = {}
    data_loaders = {}
    
    # é€‰æ‹©æ•°æ®é›†ç±»å‹
    dataset_class = SAMDataset if dataset_type == "sam" else SAMDataset  # éƒ½ä½¿ç”¨SAMæ•°æ®é›†
    
    # ğŸ”§ æ£€æŸ¥æ˜¯å¦ä½¿ç”¨æ•°æ®åˆ’åˆ†
    use_data_splitting = (
        config.train_data_dir and 
        hasattr(config, 'test_split_ratio') and
        config.test_split_ratio > 0 and 
        hasattr(config, 'use_cached_split') and
        config.use_cached_split
    )
    
    if use_data_splitting:
        print("ä½¿ç”¨æ•°æ®åˆ’åˆ†æ¨¡å¼...")
        
        try:
            from utils.data_splitter import create_data_split, print_split_summary
            
            # å‡†å¤‡ç»†èƒç±»å‹è¿‡æ»¤
            cell_types = getattr(config, '_cell_types_filter', None)
            
            # æ‰§è¡Œæ•°æ®åˆ’åˆ†
            split_result = create_data_split(
                data_dir=config.train_data_dir,
                train_ratio=config.train_split_ratio,
                val_ratio=config.val_split_ratio,
                test_ratio=config.test_split_ratio,
                cell_types=cell_types,
                split_method=config.split_method,
                seed=config.split_seed,
                split_storage_dir=config.split_storage_dir,
                use_cached=config.use_cached_split
            )
            
            # æ‰“å°åˆ’åˆ†æ‘˜è¦
            print_split_summary(split_result)
            
            # åˆ›å»ºæ•°æ®é›†
            if len(split_result.train_samples) > 0:
                datasets['train'] = dataset_class(
                    data_dir=None,
                    config=config,
                    split='train',
                    samples=split_result.train_samples
                )
                
                data_loaders['train'] = DataLoader(
                    datasets['train'],
                    batch_size=config.batch_size,
                    shuffle=True,
                    num_workers=0,  # ğŸ”§ è®¾ç½®ä¸º0é¿å…å¤šè¿›ç¨‹é—®é¢˜
                    pin_memory=config.pin_memory,
                    collate_fn=collate_fn_multi_instance
                )
            
            # éªŒè¯é›†
            if len(split_result.val_samples) > 0:
                datasets['val'] = dataset_class(
                    data_dir=None,
                    config=config,
                    split='val',
                    samples=split_result.val_samples
                )
                
                data_loaders['val'] = DataLoader(
                    datasets['val'],
                    batch_size=config.batch_size,
                    shuffle=False,
                    num_workers=0,  # ğŸ”§ è®¾ç½®ä¸º0é¿å…å¤šè¿›ç¨‹é—®é¢˜
                    pin_memory=config.pin_memory,
                    collate_fn=collate_fn_multi_instance
                )
            
            # æµ‹è¯•é›†
            if len(split_result.test_samples) > 0:
                datasets['test'] = dataset_class(
                    data_dir=None,
                    config=config,
                    split='test',
                    samples=split_result.test_samples
                )
                
                data_loaders['test'] = DataLoader(
                    datasets['test'],
                    batch_size=1,  # æµ‹è¯•æ—¶batch_size=1
                    shuffle=False,
                    num_workers=0,  # ğŸ”§ è®¾ç½®ä¸º0é¿å…å¤šè¿›ç¨‹é—®é¢˜
                    pin_memory=config.pin_memory,
                    collate_fn=collate_fn_multi_instance
                )
        
        except Exception as e:
            print(f"æ•°æ®åˆ’åˆ†å¤±è´¥ï¼Œå›é€€åˆ°ä¼ ç»Ÿæ¨¡å¼: {e}")
            use_data_splitting = False
    
    # ğŸ”§ ä¼ ç»Ÿæ¨¡å¼ï¼ˆä¸ä½¿ç”¨æ•°æ®åˆ’åˆ†ï¼‰
    if not use_data_splitting:
        print("ä½¿ç”¨ä¼ ç»Ÿæ•°æ®åŠ è½½æ¨¡å¼...")
        
        # è®­ç»ƒé›†
        if config.train_data_dir:
            datasets['train'] = dataset_class(
                data_dir=config.train_data_dir,
                config=config,
                split='train'
            )
            
            if len(datasets['train']) > 0:
                data_loaders['train'] = DataLoader(
                    datasets['train'],
                    batch_size=config.batch_size,
                    shuffle=True,
                    num_workers=0,  # ğŸ”§ è®¾ç½®ä¸º0é¿å…å¤šè¿›ç¨‹é—®é¢˜
                    pin_memory=config.pin_memory,
                    collate_fn=collate_fn_multi_instance
                )
            else:
                print("è­¦å‘Š: è®­ç»ƒé›†ä¸ºç©ºï¼Œè·³è¿‡åˆ›å»ºè®­ç»ƒæ•°æ®åŠ è½½å™¨")
        
        # éªŒè¯é›†
        if hasattr(config, 'val_data_dir') and config.val_data_dir:
            datasets['val'] = dataset_class(
                data_dir=config.val_data_dir,
                config=config,
                split='val'
            )
            
            if len(datasets['val']) > 0:
                data_loaders['val'] = DataLoader(
                    datasets['val'],
                    batch_size=config.batch_size,
                    shuffle=False,
                    num_workers=0,  # ğŸ”§ è®¾ç½®ä¸º0é¿å…å¤šè¿›ç¨‹é—®é¢˜
                    pin_memory=config.pin_memory,
                    collate_fn=collate_fn_multi_instance
                )
        elif config.train_data_dir and 'train' in datasets and len(datasets['train']) > 0:
            # å¦‚æœæ²¡æœ‰æŒ‡å®šéªŒè¯é›†ï¼Œä»è®­ç»ƒæ•°æ®ä¸­åˆ›å»º
            datasets['val'] = dataset_class(
                data_dir=config.train_data_dir,
                config=config,
                split='val'
            )
            
            if len(datasets['val']) > 0:
                data_loaders['val'] = DataLoader(
                    datasets['val'],
                    batch_size=config.batch_size,
                    shuffle=False,
                    num_workers=0,  # ğŸ”§ è®¾ç½®ä¸º0é¿å…å¤šè¿›ç¨‹é—®é¢˜
                    pin_memory=config.pin_memory,
                    collate_fn=collate_fn_multi_instance
                )
        
        # æµ‹è¯•é›†
        if hasattr(config, 'test_data_dir') and config.test_data_dir:
            datasets['test'] = dataset_class(
                data_dir=config.test_data_dir,
                config=config,
                split='test'
            )
            
            if len(datasets['test']) > 0:
                data_loaders['test'] = DataLoader(
                    datasets['test'],
                    batch_size=1,  # æµ‹è¯•æ—¶batch_size=1
                    shuffle=False,
                    num_workers=0,  # ğŸ”§ è®¾ç½®ä¸º0é¿å…å¤šè¿›ç¨‹é—®é¢˜
                    pin_memory=config.pin_memory,
                    collate_fn=collate_fn_multi_instance
                )
    
    return data_loaders


# ğŸ”§ ä¿®å¤åŸæœ‰çš„collate_fnå‡½æ•°
def collate_fn(batch):
    """å…¼å®¹æ€§collateå‡½æ•° - è°ƒç”¨å¤šå®ä¾‹ç‰ˆæœ¬"""
    return collate_fn_multi_instance(batch)

def split_dataset(data_dir: str, train_ratio: float = 0.8, val_ratio: float = 0.1):
    """å°†æ•°æ®é›†åˆ†å‰²ä¸ºè®­ç»ƒ/éªŒè¯/æµ‹è¯•é›† - å·²åºŸå¼ƒï¼Œå»ºè®®ä½¿ç”¨æ•°æ®åˆ’åˆ†åŠŸèƒ½"""
    print(f"âš ï¸  split_dataset å‡½æ•°å·²åºŸå¼ƒ")
    print(f"å»ºè®®ä½¿ç”¨æ–°çš„æ•°æ®åˆ’åˆ†åŠŸèƒ½ï¼Œæ”¯æŒç¼“å­˜å’Œæ›´å¥½çš„ç®¡ç†")
    print(f"è¯·åœ¨é…ç½®ä¸­è®¾ç½® test_split_ratio å‚æ•°")
    
    # è®¡ç®—æµ‹è¯•é›†æ¯”ä¾‹
    test_ratio = 1.0 - train_ratio - val_ratio
    
    print(f"æ•°æ®åˆ†å‰²åŠŸèƒ½å·²æ•´åˆåˆ°æ•°æ®é›†ç±»ä¸­")
    print(f"è®­ç»ƒ/éªŒè¯/æµ‹è¯•æ¯”ä¾‹: {train_ratio}/{val_ratio}/{test_ratio}")
    print(f"æ•°æ®ç›®å½•: {data_dir}")
    
    # åˆ›å»ºä¸€ä¸ªä¸´æ—¶æ•°æ®é›†æ¥éªŒè¯æ•°æ®ç»“æ„
    from config.lora_config import DataConfig
    config = DataConfig()
    config.train_split_ratio = train_ratio
    config.val_split_ratio = val_ratio
    config.test_split_ratio = test_ratio
    
    try:
        # æµ‹è¯•æ•°æ®åŠ è½½
        train_dataset = CellSegmentationDataset(data_dir, config, split='train')
        val_dataset = CellSegmentationDataset(data_dir, config, split='val')
        test_dataset = CellSegmentationDataset(data_dir, config, split='test')
        
        print(f"æ•°æ®åˆ†å‰²ç»“æœ:")
        print(f"  è®­ç»ƒé›†: {len(train_dataset)} æ ·æœ¬")
        print(f"  éªŒè¯é›†: {len(val_dataset)} æ ·æœ¬")
        print(f"  æµ‹è¯•é›†: {len(test_dataset)} æ ·æœ¬")
        
    except Exception as e:
        print(f"æ•°æ®åˆ†å‰²æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


# ğŸ”§ æ–°å¢ï¼šæ•°æ®åˆ’åˆ†ç®¡ç†åŠŸèƒ½
def list_cached_splits(split_storage_dir: str = "./data/lora_split") -> List[Dict]:
    """åˆ—å‡ºæ‰€æœ‰ç¼“å­˜çš„æ•°æ®åˆ’åˆ†"""
    try:
        splitter = DatasetSplitter("", split_storage_dir)
        return splitter.list_cached_splits()
    except Exception as e:
        print(f"åˆ—å‡ºç¼“å­˜åˆ’åˆ†å¤±è´¥: {e}")
        return []


def clean_old_splits(split_storage_dir: str = "./data/lora_split", keep_recent: int = 10):
    """æ¸…ç†æ—§çš„æ•°æ®åˆ’åˆ†æ–‡ä»¶"""
    try:
        splitter = DatasetSplitter("", split_storage_dir)
        splitter.clean_old_splits(keep_recent)
    except Exception as e:
        print(f"æ¸…ç†æ—§åˆ’åˆ†å¤±è´¥: {e}")


def preview_data_split(data_dir: str,
                      train_ratio: float = 0.8,
                      val_ratio: float = 0.1,
                      test_ratio: float = 0.1,
                      cell_types: Optional[List[str]] = None,
                      split_method: str = "random",
                      seed: int = 42,
                      split_storage_dir: str = "./data/lora_split") -> Dict:
    """é¢„è§ˆæ•°æ®åˆ’åˆ†ç»“æœï¼Œä¸å®é™…åˆ›å»ºæ–‡ä»¶"""
    try:
        splitter = DatasetSplitter(data_dir, split_storage_dir)
        
        # åˆ›å»ºä¸´æ—¶åˆ’åˆ†
        split_result = splitter.create_new_split(
            train_ratio, val_ratio, test_ratio, cell_types, split_method, seed
        )
        
        # è¿”å›ç»Ÿè®¡ä¿¡æ¯
        stats = {
            'total_samples': len(split_result.train_samples) + len(split_result.val_samples) + len(split_result.test_samples),
            'train_count': len(split_result.train_samples),
            'val_count': len(split_result.val_samples),
            'test_count': len(split_result.test_samples),
            'split_info': split_result.split_info
        }
        
        # æŒ‰ç»†èƒç±»å‹ç»Ÿè®¡
        all_samples = split_result.train_samples + split_result.val_samples + split_result.test_samples
        cell_type_counts = {}
        for sample in all_samples:
            cell_type = sample.get('cell_type', 'unknown')
            cell_type_counts[cell_type] = cell_type_counts.get(cell_type, 0) + 1
        
        stats['cell_type_distribution'] = cell_type_counts
        
        return stats
        
    except Exception as e:
        print(f"é¢„è§ˆæ•°æ®åˆ’åˆ†å¤±è´¥: {e}")
        return {}


def validate_data_split_config(train_ratio: float, val_ratio: float, test_ratio: float) -> bool:
    """éªŒè¯æ•°æ®åˆ’åˆ†é…ç½®çš„æœ‰æ•ˆæ€§"""
    total_ratio = train_ratio + val_ratio + test_ratio
    
    if abs(total_ratio - 1.0) > 1e-6:
        print(f"é”™è¯¯: æ•°æ®åˆ’åˆ†æ¯”ä¾‹æ€»å’Œå¿…é¡»ä¸º1.0ï¼Œå½“å‰ä¸º {total_ratio}")
        return False
    
    if train_ratio <= 0:
        print("é”™è¯¯: è®­ç»ƒé›†æ¯”ä¾‹å¿…é¡»å¤§äº0")
        return False
    
    if val_ratio < 0 or test_ratio < 0:
        print("é”™è¯¯: éªŒè¯é›†å’Œæµ‹è¯•é›†æ¯”ä¾‹ä¸èƒ½ä¸ºè´Ÿæ•°")
        return False
    
    if train_ratio >= 1.0:
        print("é”™è¯¯: è®­ç»ƒé›†æ¯”ä¾‹ä¸èƒ½å¤§äºç­‰äº1.0")
        return False
    
    return True


def create_balanced_cell_type_split(data_dir: str,
                                   cell_types: List[str],
                                   train_ratio: float = 0.8,
                                   val_ratio: float = 0.1,
                                   test_ratio: float = 0.1,
                                   seed: int = 42,
                                   split_storage_dir: str = "./data/lora_split") -> Dict[str, DataSplit]:
    """ä¸ºæ¯ç§ç»†èƒç±»å‹åˆ›å»ºå¹³è¡¡çš„æ•°æ®åˆ’åˆ†"""
    splits = {}
    
    for cell_type in cell_types:
        print(f"ä¸ºç»†èƒç±»å‹ {cell_type} åˆ›å»ºæ•°æ®åˆ’åˆ†...")
        
        try:
            split_result = create_data_split(
                data_dir=data_dir,
                train_ratio=train_ratio,
                val_ratio=val_ratio,
                test_ratio=test_ratio,
                cell_types=[cell_type],  # åªå¤„ç†å½“å‰ç»†èƒç±»å‹
                split_method="random",
                seed=seed,
                split_storage_dir=split_storage_dir,
                use_cached=True
            )
            
            splits[cell_type] = split_result
            print(f"  {cell_type}: train={len(split_result.train_samples)}, "
                  f"val={len(split_result.val_samples)}, test={len(split_result.test_samples)}")
            
        except Exception as e:
            print(f"ä¸ºç»†èƒç±»å‹ {cell_type} åˆ›å»ºåˆ’åˆ†å¤±è´¥: {e}")
    
    return splits


def merge_data_splits(splits: Dict[str, DataSplit]) -> DataSplit:
    """åˆå¹¶å¤šä¸ªæ•°æ®åˆ’åˆ†ç»“æœ"""
    merged_train = []
    merged_val = []
    merged_test = []
    
    for cell_type, split_result in splits.items():
        merged_train.extend(split_result.train_samples)
        merged_val.extend(split_result.val_samples)
        merged_test.extend(split_result.test_samples)
    
    # æ‰“ä¹±åˆå¹¶åçš„æ•°æ®
    import random
    random.shuffle(merged_train)
    random.shuffle(merged_val)
    random.shuffle(merged_test)
    
    # åˆ›å»ºåˆå¹¶çš„åˆ’åˆ†ä¿¡æ¯
    merged_info = {
        'merged_from': list(splits.keys()),
        'total_samples': len(merged_train) + len(merged_val) + len(merged_test),
        'train_count': len(merged_train),
        'val_count': len(merged_val),
        'test_count': len(merged_test),
        'created_at': datetime.datetime.now().isoformat()
    }
    
    return DataSplit(merged_train, merged_val, merged_test, merged_info)


def get_data_split_statistics(split_result: DataSplit) -> Dict:
    """è·å–æ•°æ®åˆ’åˆ†çš„è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯"""
    all_samples = (split_result.train_samples + 
                  split_result.val_samples + 
                  split_result.test_samples)
    
    if not all_samples:
        return {}
    
    # åŸºæœ¬ç»Ÿè®¡
    stats = {
        'total_samples': len(all_samples),
        'train_count': len(split_result.train_samples),
        'val_count': len(split_result.val_samples),
        'test_count': len(split_result.test_samples)
    }
    
    # æŒ‰ç»†èƒç±»å‹ç»Ÿè®¡
    cell_type_stats = {}
    for sample in all_samples:
        cell_type = sample.get('cell_type', 'unknown')
        if cell_type not in cell_type_stats:
            cell_type_stats[cell_type] = {'total': 0, 'train': 0, 'val': 0, 'test': 0}
        cell_type_stats[cell_type]['total'] += 1
    
    # åˆ†åˆ«ç»Ÿè®¡å„ä¸ªåˆ’åˆ†ä¸­çš„ç»†èƒç±»å‹
    for sample in split_result.train_samples:
        cell_type = sample.get('cell_type', 'unknown')
        if cell_type in cell_type_stats:
            cell_type_stats[cell_type]['train'] += 1
    
    for sample in split_result.val_samples:
        cell_type = sample.get('cell_type', 'unknown')
        if cell_type in cell_type_stats:
            cell_type_stats[cell_type]['val'] += 1
    
    for sample in split_result.test_samples:
        cell_type = sample.get('cell_type', 'unknown')
        if cell_type in cell_type_stats:
            cell_type_stats[cell_type]['test'] += 1
    
    stats['cell_type_distribution'] = cell_type_stats
    
    # æŒ‰æ•°æ®é›†ç»Ÿè®¡
    dataset_stats = {}
    for sample in all_samples:
        dataset_id = sample.get('dataset_id', 'unknown')
        if dataset_id not in dataset_stats:
            dataset_stats[dataset_id] = {'total': 0, 'train': 0, 'val': 0, 'test': 0}
        dataset_stats[dataset_id]['total'] += 1
    
    for sample in split_result.train_samples:
        dataset_id = sample.get('dataset_id', 'unknown')
        if dataset_id in dataset_stats:
            dataset_stats[dataset_id]['train'] += 1
    
    for sample in split_result.val_samples:
        dataset_id = sample.get('dataset_id', 'unknown')
        if dataset_id in dataset_stats:
            dataset_stats[dataset_id]['val'] += 1
    
    for sample in split_result.test_samples:
        dataset_id = sample.get('dataset_id', 'unknown')
        if dataset_id in dataset_stats:
            dataset_stats[dataset_id]['test'] += 1
    
    stats['dataset_distribution'] = dataset_stats
    
    return stats


def export_data_split_report(split_result: DataSplit, output_path: str):
    """å¯¼å‡ºæ•°æ®åˆ’åˆ†æŠ¥å‘Š"""
    import json
    
    # è·å–ç»Ÿè®¡ä¿¡æ¯
    stats = get_data_split_statistics(split_result)
    
    # åˆ›å»ºæŠ¥å‘Š
    report = {
        'generation_time': datetime.datetime.now().isoformat(),
        'split_info': split_result.split_info,
        'statistics': stats,
        'sample_details': {
            'train_samples': split_result.train_samples,
            'val_samples': split_result.val_samples,
            'test_samples': split_result.test_samples
        }
    }
    
    # ä¿å­˜æŠ¥å‘Š
    output_path = Path(output_path)
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    print(f"æ•°æ®åˆ’åˆ†æŠ¥å‘Šå·²å¯¼å‡ºåˆ°: {output_path}")


def load_data_split_from_report(report_path: str) -> Optional[DataSplit]:
    """ä»æŠ¥å‘Šæ–‡ä»¶åŠ è½½æ•°æ®åˆ’åˆ†"""
    try:
        with open(report_path, 'r', encoding='utf-8') as f:
            report = json.load(f)
        
        if 'sample_details' not in report:
            print(f"æŠ¥å‘Šæ–‡ä»¶æ ¼å¼ä¸æ­£ç¡®: {report_path}")
            return None
        
        sample_details = report['sample_details']
        split_info = report.get('split_info', {})
        
        return DataSplit(
            train_samples=sample_details['train_samples'],
            val_samples=sample_details['val_samples'],
            test_samples=sample_details['test_samples'],
            split_info=split_info
        )
        
    except Exception as e:
        print(f"ä»æŠ¥å‘ŠåŠ è½½æ•°æ®åˆ’åˆ†å¤±è´¥: {e}")
        return None