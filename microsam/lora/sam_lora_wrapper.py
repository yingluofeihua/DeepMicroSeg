"""
SAMä¸“ç”¨LoRAåŒ…è£…å™¨
é’ˆå¯¹SAMæ¶æ„ä¼˜åŒ–çš„LoRAå®ç°
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Dict, List, Optional, Tuple, Any
import json
from pathlib import Path

from .adapters import LoRALayer, LoRALinear
from core.sam_model_loader import SAMModelLoader


class SAMLoRAWrapper(nn.Module):
    """SAMä¸“ç”¨LoRAåŒ…è£…å™¨"""
    
    def __init__(
        self,
        sam_model_loader: SAMModelLoader,
        lora_config: Dict[str, Any]
    ):
        super().__init__()
        
        self.sam_loader = sam_model_loader
        self.config = lora_config
        self.lora_modules = {}
        
        # è·å–SAMç»„ä»¶
        self.image_encoder = sam_model_loader.image_encoder
        self.prompt_encoder = sam_model_loader.prompt_encoder
        self.mask_decoder = sam_model_loader.mask_decoder
        
        # æ·»åŠ LoRAé€‚é…å™¨
        self._add_lora_to_sam()
        
        # è®¾ç½®è®­ç»ƒæ¨¡å¼
        self._setup_training_mode()
    
    def _add_lora_to_sam(self):
        """ä¸ºSAMçš„å„ä¸ªç»„ä»¶æ·»åŠ LoRAé€‚é…å™¨"""
        apply_lora_to = self.config.get('apply_lora_to', ['image_encoder'])
        
        print(f"å°†LoRAåº”ç”¨åˆ°: {apply_lora_to}")
        
        if 'image_encoder' in apply_lora_to and self.image_encoder is not None:
            self._add_lora_to_image_encoder()
        
        if 'prompt_encoder' in apply_lora_to and self.prompt_encoder is not None:
            self._add_lora_to_prompt_encoder()
        
        if 'mask_decoder' in apply_lora_to and self.mask_decoder is not None:
            self._add_lora_to_mask_decoder()
        
        print(f"æ€»è®¡æ·»åŠ äº† {len(self.lora_modules)} ä¸ªLoRAæ¨¡å—")
    
    def _add_lora_to_image_encoder(self):
        """ä¸ºå›¾åƒç¼–ç å™¨æ·»åŠ LoRA"""
        target_modules = self.config.get('target_modules', [
            'qkv', 'proj', 'mlp', 'fc1', 'fc2'  # æ›´é€šç”¨çš„ç›®æ ‡æ¨¡å—
        ])
        
        lora_count = 0
        
        print(f"å›¾åƒç¼–ç å™¨ä¸­æœç´¢ç›®æ ‡æ¨¡å—: {target_modules}")
        
        # å…ˆæ‰“å°æ‰€æœ‰çº¿æ€§å±‚çš„åç§°ç”¨äºè°ƒè¯•
        linear_modules = []
        for name, module in self.image_encoder.named_modules():
            if isinstance(module, nn.Linear):
                linear_modules.append(name)
        
        print(f"å›¾åƒç¼–ç å™¨ä¸­çš„æ‰€æœ‰çº¿æ€§å±‚: {linear_modules[:10]}...")  # åªæ˜¾ç¤ºå‰10ä¸ª
        
        for name, module in self.image_encoder.named_modules():
            if isinstance(module, nn.Linear):
                # æ£€æŸ¥æ˜¯å¦åŒ¹é…ç›®æ ‡æ¨¡å—
                if self._should_add_lora_to_module(name, target_modules):
                    lora_module = LoRALinear(
                        module,
                        rank=self.config.get('rank', 8),
                        alpha=self.config.get('alpha', 16.0),
                        dropout=self.config.get('dropout', 0.1)
                    )
                    
                    # æ›¿æ¢æ¨¡å—
                    self._replace_module_in_image_encoder(name, lora_module)
                    self.lora_modules[f'image_encoder.{name}'] = lora_module
                    lora_count += 1
                    print(f"  ä¸º {name} æ·»åŠ LoRAé€‚é…å™¨")
        
        print(f"å›¾åƒç¼–ç å™¨æ·»åŠ äº† {lora_count} ä¸ªLoRAæ¨¡å—")
    
    def _add_lora_to_prompt_encoder(self):
        """ä¸ºæç¤ºç¼–ç å™¨æ·»åŠ LoRA"""
        # æç¤ºç¼–ç å™¨é€šå¸¸è¾ƒå°ï¼Œå¯ä»¥ä¸ºæ‰€æœ‰çº¿æ€§å±‚æ·»åŠ LoRA
        lora_count = 0
        for name, module in self.prompt_encoder.named_modules():
            if isinstance(module, nn.Linear):
                lora_module = LoRALinear(
                    module,
                    rank=self.config.get('rank', 4),  # æç¤ºç¼–ç å™¨ä½¿ç”¨æ›´å°çš„rank
                    alpha=self.config.get('alpha', 8.0),
                    dropout=self.config.get('dropout', 0.1)
                )
                
                self._replace_module_in_prompt_encoder(name, lora_module)
                self.lora_modules[f'prompt_encoder.{name}'] = lora_module
                lora_count += 1
        
        print(f"æç¤ºç¼–ç å™¨æ·»åŠ äº† {lora_count} ä¸ªLoRAæ¨¡å—")
    
    def _add_lora_to_mask_decoder(self):
        """ä¸ºæ©ç è§£ç å™¨æ·»åŠ LoRA"""
        target_modules = self.config.get('target_modules', [
            'transformer', 'iou_prediction_head', 'mask_tokens'
        ])
        
        lora_count = 0
        for name, module in self.mask_decoder.named_modules():
            if isinstance(module, nn.Linear):
                if self._should_add_lora_to_module(name, target_modules):
                    lora_module = LoRALinear(
                        module,
                        rank=self.config.get('rank', 8),
                        alpha=self.config.get('alpha', 16.0),
                        dropout=self.config.get('dropout', 0.1)
                    )
                    
                    self._replace_module_in_mask_decoder(name, lora_module)
                    self.lora_modules[f'mask_decoder.{name}'] = lora_module
                    lora_count += 1
        
        print(f"æ©ç è§£ç å™¨æ·»åŠ äº† {lora_count} ä¸ªLoRAæ¨¡å—")
    
    def _should_add_lora_to_module(self, module_name: str, target_modules: List[str]) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥ä¸ºè¯¥æ¨¡å—æ·»åŠ LoRA"""
        if not target_modules:
            return True  # å¦‚æœæ²¡æœ‰æŒ‡å®šç›®æ ‡æ¨¡å—ï¼Œåˆ™ä¸ºæ‰€æœ‰çº¿æ€§å±‚æ·»åŠ 
        
        return any(target in module_name for target in target_modules)
    
    def _replace_module_in_image_encoder(self, module_path: str, new_module: nn.Module):
        """åœ¨å›¾åƒç¼–ç å™¨ä¸­æ›¿æ¢æ¨¡å—"""
        self._replace_module(self.image_encoder, module_path, new_module)
    
    def _replace_module_in_prompt_encoder(self, module_path: str, new_module: nn.Module):
        """åœ¨æç¤ºç¼–ç å™¨ä¸­æ›¿æ¢æ¨¡å—"""
        self._replace_module(self.prompt_encoder, module_path, new_module)
    
    def _replace_module_in_mask_decoder(self, module_path: str, new_module: nn.Module):
        """åœ¨æ©ç è§£ç å™¨ä¸­æ›¿æ¢æ¨¡å—"""
        self._replace_module(self.mask_decoder, module_path, new_module)
    
    def _replace_module(self, parent_module: nn.Module, module_path: str, new_module: nn.Module):
        """åœ¨çˆ¶æ¨¡å—ä¸­æ›¿æ¢æŒ‡å®šè·¯å¾„çš„å­æ¨¡å—"""
        path_parts = module_path.split('.')
        current_module = parent_module
        
        # å¯¼èˆªåˆ°çˆ¶æ¨¡å—
        for part in path_parts[:-1]:
            current_module = getattr(current_module, part)
        
        # æ›¿æ¢æœ€åä¸€çº§æ¨¡å—
        setattr(current_module, path_parts[-1], new_module)
    
    def _setup_training_mode(self):
        """è®¾ç½®è®­ç»ƒæ¨¡å¼"""
        # æ ¹æ®é…ç½®å†»ç»“ç»„ä»¶
        if self.config.get('freeze_image_encoder', True):
            for param in self.image_encoder.parameters():
                param.requires_grad = False
            # ä½†æ˜¯è¦ç¡®ä¿LoRAå‚æ•°å¯è®­ç»ƒ
            for name, module in self.lora_modules.items():
                if 'image_encoder' in name and hasattr(module, 'lora'):
                    for param in module.lora.parameters():
                        param.requires_grad = True
        
        if self.config.get('freeze_prompt_encoder', True):
            for param in self.prompt_encoder.parameters():
                param.requires_grad = False
            for name, module in self.lora_modules.items():
                if 'prompt_encoder' in name and hasattr(module, 'lora'):
                    for param in module.lora.parameters():
                        param.requires_grad = True
        
        if self.config.get('freeze_mask_decoder', False):
            for param in self.mask_decoder.parameters():
                param.requires_grad = False
            for name, module in self.lora_modules.items():
                if 'mask_decoder' in name and hasattr(module, 'lora'):
                    for param in module.lora.parameters():
                        param.requires_grad = True
    
    def forward(self, batch_inputs: Dict[str, Any]) -> Dict[str, torch.Tensor]:
        """å‰å‘ä¼ æ’­ - 512Ã—512ç‰ˆæœ¬"""
        try:
            # æå–è¾“å…¥å¹¶è·å–è®¾å¤‡
            images = batch_inputs['images']  # âœ… [B, 3, 512, 512]
            if images.dim() == 3:                  # å•æ ·æœ¬ä½†æ²¡ batch ç»´
                images = images.unsqueeze(0)       # å˜æˆ [1,3,H,W]
            device = images.device
            # print(f"images: {images.shape}")
            
            # print(f"SAMè¾“å…¥å›¾åƒå°ºå¯¸: {images.shape}")  # [B, 3, 512, 512]
            
            # ğŸ”§ å…³é”®ä¿®å¤ï¼šSAMåŸæœ¬æœŸæœ›1024Ã—1024ï¼Œä½†ä½ ä½¿ç”¨512Ã—512
            # æœ‰ä¸¤ç§å¤„ç†æ–¹å¼ï¼š
            
            # æ–¹å¼1ï¼šä¸Šé‡‡æ ·åˆ°1024Ã—1024ï¼ˆæ¨èï¼‰
            if images.shape[-1] != 1024 or images.shape[-2] != 1024:
                # print(f"ä¸Šé‡‡æ ·å›¾åƒä» {images.shape[-2:]} åˆ° (1024, 1024)")
                images = F.interpolate(
                    images, 
                    size=(1024, 1024), 
                    mode='bilinear', 
                    align_corners=False
                )
                # print(f"ä¸Šé‡‡æ ·åå›¾åƒå°ºå¯¸: {images.shape}")  # [B, 3, 1024, 1024]
            # print(f"images11111: {images.shape}")
            # ğŸ”§ ç¡®ä¿æ‰€æœ‰æ¨¡å‹ç»„ä»¶éƒ½åœ¨æ­£ç¡®è®¾å¤‡ä¸Š
            self._ensure_models_on_device(device)
            
            # å›¾åƒç¼–ç 
            try:
                image_embeddings = self.image_encoder(images)  # è¾“å…¥ [B, 3, 1024, 1024]
                # print(f"å›¾åƒç¼–ç è¾“å‡º: {image_embeddings.shape}")  # [B, 256, 64, 64]
            except Exception as e:
                print(f"å›¾åƒç¼–ç å¤±è´¥: {e}")
                raise
            
            # æ‰¹é‡å¤„ç†æ¯ä¸ªæ ·æœ¬
            batch_outputs = []
            batch_size = images.shape[0]
            
            for i in range(batch_size):
                try:
                    single_image_embedding = image_embeddings[i:i+1]
                    
                    # æç¤ºç¼–ç 
                    sparse_embeddings, dense_embeddings = self._encode_prompts(
                        batch_inputs.get('point_coords', []), 
                        batch_inputs.get('point_labels', []), 
                        batch_inputs.get('boxes', []), 
                        batch_inputs.get('mask_inputs', None), 
                        i, device
                    )
                    
                    # è·å–ä½ç½®ç¼–ç 
                    try:
                        image_pe = self.prompt_encoder.get_dense_pe().to(device)
                    except:
                        image_pe = torch.zeros(1, 256, 64, 64, device=device)
                    
                    # æ©ç è§£ç 
                    low_res_masks, iou_predictions = self.mask_decoder(
                        image_embeddings=single_image_embedding,
                        image_pe=image_pe,
                        sparse_prompt_embeddings=sparse_embeddings,
                        dense_prompt_embeddings=dense_embeddings,
                        multimask_output=batch_inputs.get('multimask_output', False)
                    )
                    
                    # print(f"æ©ç è§£ç è¾“å‡º: {low_res_masks.shape}")  # [1, 1, 256, 256]
                    
                    # ğŸ”§ å…³é”®ï¼šå°†256Ã—256çš„è¾“å‡ºè°ƒæ•´åˆ°512Ã—512
                    if low_res_masks.shape[-1] != 512:
                        # print(f"è°ƒæ•´æ©ç ä» {low_res_masks.shape[-2:]} åˆ° (512, 512)")
                        low_res_masks = F.interpolate(
                            low_res_masks,
                            size=(512, 512),
                            mode='bilinear',
                            align_corners=False
                        )
                        # print(f"è°ƒæ•´åæ©ç å°ºå¯¸: {low_res_masks.shape}")  # [1, 1, 512, 512]
                    
                    batch_outputs.append({
                        'masks': low_res_masks,      # âœ… [1, 1, 512, 512]
                        'iou_predictions': iou_predictions
                    })
                    
                except Exception as e:
                    print(f"å¤„ç†æ ·æœ¬ {i} å¤±è´¥: {e}")
                    # è¿”å›512Ã—512çš„é»˜è®¤è¾“å‡º
                    batch_outputs.append({
                        'masks': torch.zeros(1, 1, 512, 512, device=device),
                        'iou_predictions': torch.zeros(1, 1, device=device)
                    })
            
            # åˆå¹¶æ‰¹é‡è¾“å‡º
            result = self._merge_batch_outputs(batch_outputs)
            # print(f"æœ€ç»ˆè¾“å‡ºæ©ç å°ºå¯¸: {result['masks'].shape}")  # [B, 1, 512, 512]
            
            return result
            
        except Exception as e:
            print(f"SAM forwardä¼ æ’­å¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()
            
            # è¿”å›512Ã—512çš„é»˜è®¤è¾“å‡º
            device = batch_inputs['images'].device
            batch_size = batch_inputs['images'].shape[0]
            return {
                'masks': torch.zeros(batch_size, 1, 512, 512, device=device),
                'iou_predictions': torch.zeros(batch_size, 1, device=device)
            }
        
    def _ensure_models_on_device(self, device: torch.device):
        """ç¡®ä¿æ‰€æœ‰æ¨¡å‹ç»„ä»¶éƒ½åœ¨æŒ‡å®šè®¾å¤‡ä¸Š"""
        
        # ç§»åŠ¨ä¸»è¦ç»„ä»¶
        if self.image_encoder is not None:
            self.image_encoder = self.image_encoder.to(device)
        
        if self.prompt_encoder is not None:
            self.prompt_encoder = self.prompt_encoder.to(device)
        
        if self.mask_decoder is not None:
            self.mask_decoder = self.mask_decoder.to(device)
        
        # ğŸ”§ ç§»åŠ¨æ‰€æœ‰LoRAæ¨¡å—
        for name, lora_module in self.lora_modules.items():
            if hasattr(lora_module, 'lora'):
                lora_module.lora = lora_module.lora.to(device)
            lora_module = lora_module.to(device)

    def _encode_prompts(self, point_coords, point_labels, boxes, mask_inputs, batch_idx, device):
        """ç¼–ç æç¤ºä¿¡æ¯ - ç¡®ä¿è®¾å¤‡ä¸€è‡´æ€§"""
        
        # å¤„ç†ç‚¹æç¤º
        points = None
        if (isinstance(point_coords, list) and batch_idx < len(point_coords) and 
            isinstance(point_coords[batch_idx], torch.Tensor) and len(point_coords[batch_idx]) > 0):
            
            batch_point_coords = point_coords[batch_idx].to(device)
            batch_point_labels = (point_labels[batch_idx].to(device) 
                                if isinstance(point_labels, list) and batch_idx < len(point_labels) 
                                else None)
            
            if batch_point_labels is not None and len(batch_point_labels) > 0:
                points = (batch_point_coords.unsqueeze(0), batch_point_labels.unsqueeze(0))
            else:
                labels = torch.ones(len(batch_point_coords), dtype=torch.long, device=device)
                points = (batch_point_coords.unsqueeze(0), labels.unsqueeze(0))
        
        # å¤„ç†æ¡†æç¤º
        box = None
        if (isinstance(boxes, list) and batch_idx < len(boxes) and 
            isinstance(boxes[batch_idx], torch.Tensor) and len(boxes[batch_idx]) > 0):
            
            batch_boxes = boxes[batch_idx].to(device)
            box = batch_boxes[0].unsqueeze(0)
        
        # å¤„ç†æ©ç æç¤º
        mask = None
        if (isinstance(mask_inputs, list) and batch_idx < len(mask_inputs) and 
            mask_inputs[batch_idx] is not None):
            mask = mask_inputs[batch_idx].to(device)
        
        # ä½¿ç”¨æç¤ºç¼–ç å™¨ç¼–ç 
        try:
            sparse_embeddings, dense_embeddings = self.prompt_encoder(
                points=points,
                boxes=box,
                masks=mask
            )
        except Exception as e:
            print(f"æç¤ºç¼–ç å¤±è´¥: {e}")
            # åˆ›å»ºé»˜è®¤çš„ç©ºæç¤ºç¼–ç 
            sparse_embeddings = torch.zeros(1, 0, 256, device=device)
            dense_embeddings = torch.zeros(1, 256, 64, 64, device=device)
        
        return sparse_embeddings, dense_embeddings
    
    def _merge_batch_outputs(self, batch_outputs: List[Dict]) -> Dict[str, torch.Tensor]:
        """åˆå¹¶æ‰¹é‡è¾“å‡º"""
        if not batch_outputs:
            return {'masks': torch.empty(0), 'iou_predictions': torch.empty(0)}
        
        # åˆå¹¶æ©ç 
        masks = torch.cat([output['masks'] for output in batch_outputs], dim=0)
        iou_predictions = torch.cat([output['iou_predictions'] for output in batch_outputs], dim=0)
        
        return {
            'masks': masks,
            'iou_predictions': iou_predictions
        }
    
    def save_lora_weights(self, save_path: str):
        """ä¿å­˜LoRAæƒé‡"""
        save_path = Path(save_path)
        save_path.mkdir(parents=True, exist_ok=True)
        
        # ä¿å­˜LoRAæƒé‡
        lora_state_dict = {}
        for name, module in self.lora_modules.items():
            if hasattr(module, 'lora'):
                lora_state_dict[f"{name}.lora_A.weight"] = module.lora.lora_A.weight
                lora_state_dict[f"{name}.lora_B.weight"] = module.lora.lora_B.weight
                if module.lora.lora_B.bias is not None:
                    lora_state_dict[f"{name}.lora_B.bias"] = module.lora.lora_B.bias
        
        torch.save(lora_state_dict, save_path / "sam_lora_weights.pth")
        
        # ä¿å­˜é…ç½®
        config_to_save = self.config.copy()
        config_to_save['model_type'] = self.sam_loader.model_type
        
        with open(save_path / "sam_lora_config.json", 'w') as f:
            json.dump(config_to_save, f, indent=2)
        
        print(f"SAM LoRAæƒé‡å·²ä¿å­˜åˆ°: {save_path}")
    
    def load_lora_weights(self, load_path: str):
        """åŠ è½½LoRAæƒé‡"""
        load_path = Path(load_path)
        
        # åŠ è½½æƒé‡
        weights_file = load_path / "sam_lora_weights.pth"
        if weights_file.exists():
            lora_state_dict = torch.load(weights_file, map_location='cpu')
            
            # åŠ è½½æƒé‡åˆ°å¯¹åº”æ¨¡å—
            for name, module in self.lora_modules.items():
                if hasattr(module, 'lora'):
                    if f"{name}.lora_A.weight" in lora_state_dict:
                        module.lora.lora_A.weight.data = lora_state_dict[f"{name}.lora_A.weight"]
                    if f"{name}.lora_B.weight" in lora_state_dict:
                        module.lora.lora_B.weight.data = lora_state_dict[f"{name}.lora_B.weight"]
                    if f"{name}.lora_B.bias" in lora_state_dict:
                        module.lora.lora_B.bias.data = lora_state_dict[f"{name}.lora_B.bias"]
            
            print(f"SAM LoRAæƒé‡å·²ä» {load_path} åŠ è½½")
        else:
            print(f"è­¦å‘Š: æœªæ‰¾åˆ°LoRAæƒé‡æ–‡ä»¶ {weights_file}")
    
    def merge_and_save_full_model(self, save_path: str):
        """åˆå¹¶LoRAæƒé‡å¹¶ä¿å­˜å®Œæ•´SAMæ¨¡å‹"""
        # åˆå¹¶æ‰€æœ‰LoRAæƒé‡
        for module in self.lora_modules.values():
            if hasattr(module, 'merge_weights'):
                module.merge_weights()
        
        # ä¿å­˜åˆå¹¶åçš„SAMæ¨¡å‹
        self.sam_loader.save_model_state(save_path)
        print(f"åˆå¹¶çš„SAMæ¨¡å‹å·²ä¿å­˜åˆ°: {save_path}")
        
        # æ¢å¤LoRAçŠ¶æ€
        for module in self.lora_modules.values():
            if hasattr(module, 'unmerge_weights'):
                module.unmerge_weights()
    
    def get_trainable_parameters(self) -> Dict[str, int]:
        """è·å–å¯è®­ç»ƒå‚æ•°ç»Ÿè®¡"""
        total_params = 0
        trainable_params = 0
        lora_params = 0
        
        # ç»Ÿè®¡æ‰€æœ‰å‚æ•°
        for name, param in self.named_parameters():
            total_params += param.numel()
            if param.requires_grad:
                trainable_params += param.numel()
                if 'lora' in name.lower():
                    lora_params += param.numel()
        
        return {
            'total_parameters': total_params,
            'trainable_parameters': trainable_params,
            'lora_parameters': lora_params,
            'trainable_percentage': 100 * trainable_params / total_params if total_params > 0 else 0,
            'lora_percentage': 100 * lora_params / total_params if total_params > 0 else 0
        }
    
    def print_model_info(self):
        """æ‰“å°æ¨¡å‹ä¿¡æ¯"""
        info = self.get_trainable_parameters()
        print(f"\nSAM LoRAæ¨¡å‹ä¿¡æ¯:")
        print(f"  æ€»å‚æ•°æ•°: {info['total_parameters']:,}")
        print(f"  å¯è®­ç»ƒå‚æ•°æ•°: {info['trainable_parameters']:,}")
        print(f"  LoRAå‚æ•°æ•°: {info['lora_parameters']:,}")
        print(f"  å¯è®­ç»ƒå‚æ•°æ¯”ä¾‹: {info['trainable_percentage']:.2f}%")
        print(f"  LoRAå‚æ•°æ¯”ä¾‹: {info['lora_percentage']:.2f}%")
        print(f"  LoRAæ¨¡å—æ•°: {len(self.lora_modules)}")
        
        # æŒ‰ç»„ä»¶åˆ†ç»„æ˜¾ç¤ºLoRAæ¨¡å—
        component_counts = {}
        for name in self.lora_modules.keys():
            component = name.split('.')[0]
            component_counts[component] = component_counts.get(component, 0) + 1
        
        print(f"  LoRAæ¨¡å—åˆ†å¸ƒ:")
        for component, count in component_counts.items():
            print(f"    {component}: {count} ä¸ªæ¨¡å—")


def create_sam_lora_model(model_type: str, lora_config: Dict[str, Any], device: str = "cuda") -> Optional[SAMLoRAWrapper]:
    """åˆ›å»ºSAM LoRAæ¨¡å‹çš„ä¾¿æ·å‡½æ•°"""
    try:
        # åŠ è½½SAMæ¨¡å‹
        from core.sam_model_loader import load_sam_for_training
        
        sam_loader = load_sam_for_training(
            model_type=model_type,
            device=device,
            freeze_image_encoder=lora_config.get('freeze_image_encoder', True),
            freeze_prompt_encoder=lora_config.get('freeze_prompt_encoder', True),
            freeze_mask_decoder=lora_config.get('freeze_mask_decoder', False)
        )
        
        if sam_loader is None:
            print("SAMæ¨¡å‹åŠ è½½å¤±è´¥")
            return None
        
        # åˆ›å»ºLoRAåŒ…è£…å™¨
        sam_lora_model = SAMLoRAWrapper(sam_loader, lora_config)
        
        return sam_lora_model
        
    except Exception as e:
        print(f"åˆ›å»ºSAM LoRAæ¨¡å‹å¤±è´¥: {e}")
        return None


def load_sam_lora_model(model_type: str, lora_path: str, device: str = "cuda") -> Optional[SAMLoRAWrapper]:
    """åŠ è½½å·²è®­ç»ƒçš„SAM LoRAæ¨¡å‹"""
    try:
        lora_path = Path(lora_path)
        
        # åŠ è½½LoRAé…ç½®
        config_file = lora_path / "sam_lora_config.json"
        if config_file.exists():
            with open(config_file, 'r') as f:
                lora_config = json.load(f)
        else:
            # ä½¿ç”¨é»˜è®¤é…ç½®
            lora_config = {
                'rank': 8, 
                'alpha': 16.0, 
                'dropout': 0.1,
                'apply_lora_to': ['image_encoder']
            }
            print("ä½¿ç”¨é»˜è®¤LoRAé…ç½®")
        
        # åˆ›å»ºSAM LoRAæ¨¡å‹
        sam_lora_model = create_sam_lora_model(model_type, lora_config, device)
        
        if sam_lora_model is None:
            return None
        
        # åŠ è½½LoRAæƒé‡
        sam_lora_model.load_lora_weights(lora_path)
        
        return sam_lora_model
        
    except Exception as e:
        print(f"åŠ è½½SAM LoRAæ¨¡å‹å¤±è´¥: {e}")
        return None