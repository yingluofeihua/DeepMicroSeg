'''
 # @ Author: Zhenhua Chen
 # @ Create Time: 2025-05-29 05:39:19
 # @ Email: Zhenhua.Chen@gmail.com
 # @ Description:
 '''

# test_batch_fixed_with_real_data.py - ä½¿ç”¨çœŸå®æ•°æ®çš„æ‰¹é‡æ¨ç†æµ‹è¯•
import sys
from pathlib import Path
sys.path.append(str(Path(__file__).parent))

import torch
import numpy as np
import time
import json
from tqdm import tqdm
from typing import List, Dict, Optional

class RealDataBatchInferenceTest:
    """ä½¿ç”¨çœŸå®æµ‹è¯•æ•°æ®çš„æ‰¹é‡æ¨ç†æµ‹è¯•"""
    
    def __init__(self, lora_model_path: str, split_file: str):
        self.lora_model_path = lora_model_path
        self.split_file = split_file
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.model = None
        self.test_samples = []
        
    def load_test_samples(self):
        """ä»æ•°æ®åˆ’åˆ†æ–‡ä»¶åŠ è½½æµ‹è¯•æ ·æœ¬"""
        print(f"æ­£åœ¨åŠ è½½æ•°æ®åˆ’åˆ†æ–‡ä»¶: {self.split_file}")
        
        try:
            # åŠ è½½æ•°æ®åˆ’åˆ†
            with open(self.split_file, 'r', encoding='utf-8') as f:
                split_data = json.load(f)
            
            from utils.data_splitter import DataSplit
            split_result = DataSplit.from_dict(split_data)
            self.test_samples = split_result.test_samples
            
            print(f"åŠ è½½äº† {len(self.test_samples)} ä¸ªæµ‹è¯•æ ·æœ¬")
            
            # éªŒè¯æ ·æœ¬è·¯å¾„çš„æœ‰æ•ˆæ€§
            valid_samples = []
            for sample in self.test_samples:
                img_path = Path(sample['image_path'])
                mask_path = Path(sample['mask_path'])
                if img_path.exists() and mask_path.exists():
                    valid_samples.append(sample)
                else:
                    print(f"è­¦å‘Š: æ ·æœ¬è·¯å¾„ä¸å­˜åœ¨ - {sample['sample_id']}")
            
            self.test_samples = valid_samples
            print(f"æœ‰æ•ˆæµ‹è¯•æ ·æœ¬æ•°: {len(self.test_samples)}")
            
            return len(self.test_samples) > 0
            
        except Exception as e:
            print(f"åŠ è½½æµ‹è¯•æ ·æœ¬å¤±è´¥: {e}")
            return False
    
    def load_fixed_model(self):
        """åŠ è½½ä¿®å¤ç‰ˆæœ¬çš„LoRAæ¨¡å‹"""
        from lora.stable_sam_lora_wrapper import load_stable_sam_lora_model as load_sam_lora_model
        
        print("æ­£åœ¨åŠ è½½ä¿®å¤ç‰ˆæœ¬çš„LoRAæ¨¡å‹...")
        self.model = load_sam_lora_model("vit_b_lm", self.lora_model_path, str(self.device))
        
        if self.model is None:
            print("âŒ ä¿®å¤ç‰ˆæœ¬æ¨¡å‹åŠ è½½å¤±è´¥")
            return False
        
        self.model = self.model.to(self.device)
        self.model.eval()
        print(f"âœ… ä¿®å¤ç‰ˆæœ¬æ¨¡å‹åŠ è½½æˆåŠŸï¼Œè®¾å¤‡: {self.device}")
        return True
    
    def load_real_images(self, sample_indices: List[int]) -> Optional[torch.Tensor]:
        """åŠ è½½çœŸå®å›¾åƒæ•°æ®"""
        from utils.file_utils import load_image
        
        images = []
        valid_indices = []
        
        for idx in sample_indices:
            if idx >= len(self.test_samples):
                continue
                
            sample = self.test_samples[idx]
            img_path = sample['image_path']
            
            try:
                # åŠ è½½å›¾åƒ
                image = load_image(img_path, convert_to_grayscale=False)
                if image is None:
                    continue
                
                # è½¬æ¢ä¸ºå¼ é‡
                if len(image.shape) == 2:
                    # ç°åº¦å›¾è½¬RGB
                    image = np.stack([image] * 3, axis=-1)
                elif image.shape[-1] == 1:
                    image = np.repeat(image, 3, axis=-1)
                
                # è½¬æ¢ä¸ºå¼ é‡å¹¶å½’ä¸€åŒ–
                image_tensor = torch.from_numpy(image).permute(2, 0, 1).float() / 255.0
                
                # è°ƒæ•´åˆ°1024x1024
                if image_tensor.shape[-2:] != (1024, 1024):
                    image_tensor = torch.nn.functional.interpolate(
                        image_tensor.unsqueeze(0), 
                        size=(1024, 1024), 
                        mode='bilinear', 
                        align_corners=False
                    ).squeeze(0)
                
                images.append(image_tensor)
                valid_indices.append(idx)
                
            except Exception as e:
                print(f"åŠ è½½å›¾åƒå¤±è´¥ {img_path}: {e}")
                continue
        
        if not images:
            return None
        
        batch_images = torch.stack(images).to(self.device)
        print(f"æˆåŠŸåŠ è½½ {len(images)} å¼ çœŸå®å›¾åƒï¼Œå½¢çŠ¶: {batch_images.shape}")
        
        return batch_images, valid_indices
    
    def test_batch_sizes_with_real_data(self, batch_sizes: List[int] = [1, 2, 4, 8, 16]):
        """ä½¿ç”¨çœŸå®æ•°æ®æµ‹è¯•ä¸åŒçš„æ‰¹æ¬¡å¤§å°"""
        
        # å…ˆåŠ è½½æµ‹è¯•æ ·æœ¬
        if not self.load_test_samples():
            print("âŒ æ— æ³•åŠ è½½æµ‹è¯•æ ·æœ¬")
            return
        
        # åŠ è½½æ¨¡å‹
        if not self.load_fixed_model():
            print("âŒ æ— æ³•åŠ è½½æ¨¡å‹")
            return
        
        print(f"\n{'='*80}")
        print("ğŸ§ª ä½¿ç”¨çœŸå®æ•°æ®æµ‹è¯•ä¿®å¤ç‰ˆæœ¬çš„æ‰¹é‡æ¨ç†")
        print(f"{'='*80}")
        print(f"æµ‹è¯•æ ·æœ¬æ€»æ•°: {len(self.test_samples)}")
        
        results = {}
        
        for batch_size in batch_sizes:
            print(f"\nğŸ“Š æµ‹è¯• Batch Size = {batch_size}")
            print("-" * 50)
            
            # æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„æ ·æœ¬
            if batch_size > len(self.test_samples):
                print(f"   âš ï¸  æ‰¹æ¬¡å¤§å° {batch_size} è¶…è¿‡å¯ç”¨æ ·æœ¬æ•° {len(self.test_samples)}ï¼Œè·³è¿‡")
                results[batch_size] = {
                    'success': False,
                    'error': f'Insufficient samples ({len(self.test_samples)} < {batch_size})'
                }
                continue
            
            try:
                # é€‰æ‹©æ ·æœ¬ç´¢å¼•
                sample_indices = list(range(batch_size))
                
                # åŠ è½½çœŸå®å›¾åƒ
                loaded_data = self.load_real_images(sample_indices)
                if loaded_data is None:
                    print(f"   âŒ æ— æ³•åŠ è½½è¶³å¤Ÿçš„æœ‰æ•ˆå›¾åƒ")
                    results[batch_size] = {
                        'success': False,
                        'error': 'Failed to load valid images'
                    }
                    continue
                
                real_images, valid_indices = loaded_data
                actual_batch_size = real_images.shape[0]
                
                print(f"   ğŸ“· å®é™…åŠ è½½å›¾åƒæ•°: {actual_batch_size}")
                
                # å‡†å¤‡è¾“å…¥
                batch_inputs = {
                    'images': real_images,
                    'point_coords': [],
                    'point_labels': [],
                    'boxes': [],
                    'mask_inputs': None,
                    'multimask_output': False
                }
                
                # æµ‹è¯•æ¨ç†
                start_time = time.time()
                
                with torch.no_grad():
                    outputs = self.model(batch_inputs)
                
                inference_time = time.time() - start_time
                
                # éªŒè¯è¾“å‡º
                masks = outputs['masks']
                iou_predictions = outputs['iou_predictions']
                
                print(f"   âœ… æ¨ç†æˆåŠŸ!")
                print(f"   ğŸ“ è¾“å‡ºå½¢çŠ¶:")
                print(f"      æ©ç : {masks.shape}")
                print(f"      IoUé¢„æµ‹: {iou_predictions.shape}")
                print(f"   â±ï¸  æ¨ç†æ—¶é—´: {inference_time:.4f}s")
                print(f"   ğŸ“ˆ å¹³å‡æ—¶é—´/å›¾åƒ: {inference_time/actual_batch_size:.4f}s")
                
                # æ˜¾ç¤ºå¤„ç†çš„æ ·æœ¬ä¿¡æ¯
                print(f"   ğŸ“‹ å¤„ç†çš„æ ·æœ¬:")
                for i, idx in enumerate(valid_indices[:3]):  # åªæ˜¾ç¤ºå‰3ä¸ª
                    sample = self.test_samples[idx]
                    print(f"      {i+1}. {sample['sample_id']} ({sample['cell_type']})")
                if len(valid_indices) > 3:
                    print(f"      ... è¿˜æœ‰ {len(valid_indices) - 3} ä¸ªæ ·æœ¬")
                
                # éªŒè¯è¾“å‡ºçš„åˆç†æ€§
                validation_result = self._validate_outputs(masks, iou_predictions, actual_batch_size)
                if validation_result['valid']:
                    print(f"   âœ… è¾“å‡ºéªŒè¯é€šè¿‡")
                else:
                    print(f"   âš ï¸  è¾“å‡ºéªŒè¯è­¦å‘Š: {validation_result['warnings']}")
                
                # ä¿å­˜ç»“æœ
                results[batch_size] = {
                    'success': True,
                    'inference_time': inference_time,
                    'time_per_image': inference_time / actual_batch_size,
                    'actual_batch_size': actual_batch_size,
                    'processed_samples': [self.test_samples[idx]['sample_id'] for idx in valid_indices],
                    'output_shapes': {
                        'masks': list(masks.shape),
                        'iou_predictions': list(iou_predictions.shape)
                    },
                    'validation': validation_result
                }
                
            except Exception as e:
                print(f"   âŒ æ¨ç†å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
                results[batch_size] = {
                    'success': False,
                    'error': str(e)
                }
        
        # æ‰“å°æ€»ç»“
        self._print_test_summary(results)
        return results
    
    def _validate_outputs(self, masks: torch.Tensor, iou_predictions: torch.Tensor, batch_size: int) -> dict:
        """éªŒè¯è¾“å‡ºçš„åˆç†æ€§"""
        validation = {'valid': True, 'warnings': []}
        
        # æ£€æŸ¥å½¢çŠ¶
        expected_mask_shape = (batch_size, 1, 256, 256)
        expected_iou_shape = (batch_size, 1)
        
        if masks.shape != expected_mask_shape:
            validation['warnings'].append(f"æ©ç å½¢çŠ¶å¼‚å¸¸: æœŸæœ›{expected_mask_shape}, å®é™…{masks.shape}")
        
        if iou_predictions.shape != expected_iou_shape:
            validation['warnings'].append(f"IoUå½¢çŠ¶å¼‚å¸¸: æœŸæœ›{expected_iou_shape}, å®é™…{iou_predictions.shape}")
        
        # æ£€æŸ¥æ•°å€¼èŒƒå›´
        mask_min, mask_max = masks.min().item(), masks.max().item()
        iou_min, iou_max = iou_predictions.min().item(), iou_predictions.max().item()
        
        if mask_min < -10 or mask_max > 10:
            validation['warnings'].append(f"æ©ç æ•°å€¼èŒƒå›´å¼‚å¸¸: [{mask_min:.3f}, {mask_max:.3f}]")
        
        if iou_min < 0 or iou_max > 1:
            validation['warnings'].append(f"IoUæ•°å€¼èŒƒå›´å¼‚å¸¸: [{iou_min:.3f}, {iou_max:.3f}]")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰NaNæˆ–Inf
        if torch.isnan(masks).any():
            validation['warnings'].append("æ©ç åŒ…å«NaNå€¼")
        
        if torch.isinf(masks).any():
            validation['warnings'].append("æ©ç åŒ…å«Infå€¼")
        
        if torch.isnan(iou_predictions).any():
            validation['warnings'].append("IoUé¢„æµ‹åŒ…å«NaNå€¼")
        
        if validation['warnings']:
            validation['valid'] = False
        
        return validation
    
    def _print_test_summary(self, results: dict):
        """æ‰“å°æµ‹è¯•æ€»ç»“"""
        print(f"\n{'='*80}")
        print("ğŸ“‹ çœŸå®æ•°æ®æ‰¹é‡æ¨ç†æµ‹è¯•æ€»ç»“")
        print(f"{'='*80}")
        
        successful_batches = [bs for bs, result in results.items() if result['success']]
        failed_batches = [bs for bs, result in results.items() if not result['success']]
        
        print(f"âœ… æˆåŠŸçš„æ‰¹æ¬¡å¤§å°: {successful_batches}")
        if failed_batches:
            print(f"âŒ å¤±è´¥çš„æ‰¹æ¬¡å¤§å°: {failed_batches}")
            print(f"å¤±è´¥åŸå› :")
            for bs in failed_batches:
                print(f"  {bs}: {results[bs]['error']}")
        
        if successful_batches:
            print(f"\nğŸ“Š æ€§èƒ½ç»Ÿè®¡:")
            print(f"{'æ‰¹æ¬¡å¤§å°':<8} {'å®é™…æ‰¹æ¬¡':<8} {'æ€»æ—¶é—´(s)':<12} {'å¹³å‡æ—¶é—´/å›¾åƒ(s)':<18} {'ååé‡(å›¾åƒ/s)':<15}")
            print("-" * 70)
            
            for batch_size in successful_batches:
                result = results[batch_size]
                actual_size = result['actual_batch_size']
                total_time = result['inference_time']
                time_per_image = result['time_per_image']
                throughput = 1.0 / time_per_image
                
                print(f"{batch_size:<8} {actual_size:<8} {total_time:<12.4f} {time_per_image:<18.4f} {throughput:<15.2f}")
        
        print(f"\nğŸ¯ ç»“è®º:")
        if len(successful_batches) == len(results):
            print("   âœ… æ‰€æœ‰æ‰¹æ¬¡å¤§å°éƒ½æˆåŠŸï¼çœŸå®æ•°æ®æ‰¹é‡æ¨ç†å®Œå…¨æ­£å¸¸ï¼")
        elif successful_batches:
            max_successful = max(successful_batches)
            print(f"   âš ï¸  éƒ¨åˆ†æˆåŠŸï¼Œæœ€å¤§æ”¯æŒæ‰¹æ¬¡å¤§å°: {max_successful}")
        else:
            print("   âŒ æ‰€æœ‰æ‰¹æ¬¡éƒ½å¤±è´¥ï¼Œéœ€è¦è¿›ä¸€æ­¥è°ƒè¯•")
    
    def test_specific_samples(self, sample_indices: List[int]):
        """æµ‹è¯•ç‰¹å®šçš„æ ·æœ¬"""
        if not self.test_samples:
            print("âŒ è¯·å…ˆåŠ è½½æµ‹è¯•æ ·æœ¬")
            return
        
        if not self.model:
            if not self.load_fixed_model():
                return
        
        print(f"\nğŸ¯ æµ‹è¯•ç‰¹å®šæ ·æœ¬ (ç´¢å¼•: {sample_indices})")
        print("-" * 50)
        
        try:
            # åŠ è½½æŒ‡å®šæ ·æœ¬çš„å›¾åƒ
            loaded_data = self.load_real_images(sample_indices)
            if loaded_data is None:
                print("âŒ æ— æ³•åŠ è½½æŒ‡å®šæ ·æœ¬çš„å›¾åƒ")
                return
            
            real_images, valid_indices = loaded_data
            
            # å‡†å¤‡è¾“å…¥
            batch_inputs = {
                'images': real_images,
                'point_coords': [],
                'point_labels': [],
                'boxes': [],
                'mask_inputs': None,
                'multimask_output': False
            }
            
            # æ¨ç†
            start_time = time.time()
            with torch.no_grad():
                outputs = self.model(batch_inputs)
            inference_time = time.time() - start_time
            
            print(f"âœ… æ¨ç†æˆåŠŸ!")
            print(f"ğŸ“ è¾“å‡ºå½¢çŠ¶: æ©ç {outputs['masks'].shape}, IoU{outputs['iou_predictions'].shape}")
            print(f"â±ï¸  æ¨ç†æ—¶é—´: {inference_time:.4f}s")
            print(f"ğŸ“ˆ å¹³å‡æ—¶é—´/å›¾åƒ: {inference_time/len(valid_indices):.4f}s")
            
            # æ˜¾ç¤ºå¤„ç†çš„æ ·æœ¬è¯¦æƒ…
            print(f"\nğŸ“‹ å¤„ç†çš„æ ·æœ¬è¯¦æƒ…:")
            for i, idx in enumerate(valid_indices):
                sample = self.test_samples[idx]
                mask_val = torch.sigmoid(outputs['masks'][i]).mean().item()
                iou_val = outputs['iou_predictions'][i].item()
                print(f"  {i+1}. {sample['sample_id']} ({sample['cell_type']})")
                print(f"     æ©ç å‡å€¼: {mask_val:.4f}, IoUé¢„æµ‹: {iou_val:.4f}")
                print(f"     å›¾åƒè·¯å¾„: {sample['image_path']}")
            
            return outputs
            
        except Exception as e:
            print(f"âŒ æµ‹è¯•ç‰¹å®šæ ·æœ¬å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    # é…ç½®è·¯å¾„
    lora_model_path = "/LD-FS/home/zhenhuachen/code/github/DeepMicroSeg/data/lora_model/lora_model_293t_train0_val10_test90/lora_finetune_vit_b_lm_r8/final_model"
    split_file = "/LD-FS/home/zhenhuachen/code/github/DeepMicroSeg/data/lora_split/split_0.05_0.00_0.95_293T_32f483d5bd91b97e.json"
    
    print("ğŸš€ å¼€å§‹ä½¿ç”¨çœŸå®æ•°æ®æµ‹è¯•ä¿®å¤ç‰ˆæœ¬çš„æ‰¹é‡æ¨ç†")
    print(f"LoRAæ¨¡å‹è·¯å¾„: {lora_model_path}")
    print(f"æ•°æ®åˆ’åˆ†æ–‡ä»¶: {split_file}")
    
    # åˆ›å»ºæµ‹è¯•å®ä¾‹
    tester = RealDataBatchInferenceTest(lora_model_path, split_file)
    
    # æµ‹è¯•1: ä¸åŒæ‰¹æ¬¡å¤§å°
    print("\n" + "="*80)
    print("æµ‹è¯•1: ä¸åŒæ‰¹æ¬¡å¤§å°çš„çœŸå®æ•°æ®æ¨ç†èƒ½åŠ›")
    print("="*80)
    batch_results = tester.test_batch_sizes_with_real_data([1, 2, 4, 8, 16])
    
    # æµ‹è¯•2: æµ‹è¯•ç‰¹å®šæ ·æœ¬
    print("\n" + "="*80)
    print("æµ‹è¯•2: ç‰¹å®šæ ·æœ¬è¯¦ç»†æµ‹è¯•")
    print("="*80)
    if tester.test_samples:
        # æµ‹è¯•å‰5ä¸ªæ ·æœ¬
        sample_indices = list(range(min(5, len(tester.test_samples))))
        tester.test_specific_samples(sample_indices)
    
    print(f"\n{'='*80}")
    print("ğŸ‰ çœŸå®æ•°æ®æ‰¹é‡æ¨ç†æµ‹è¯•å®Œæˆ!")
    print(f"{'='*80}")


if __name__ == "__main__":
    main()