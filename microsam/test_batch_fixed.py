'''
 # @ Author: Zhenhua Chen
 # @ Create Time: 2025-05-28 03:13:12
 # @ Email: Zhenhua.Chen@gmail.com
 # @ Description:
 '''

# test_batch_fixed.py - æµ‹è¯•ä¿®å¤ç‰ˆæœ¬çš„æ‰¹é‡æ¨ç†
import sys
from pathlib import Path
sys.path.append(str(Path(__file__).parent))

import torch
import numpy as np
import time
from tqdm import tqdm

class FixedBatchInferenceTest:
    """ä¿®å¤ç‰ˆæœ¬çš„æ‰¹é‡æ¨ç†æµ‹è¯•"""
    
    def __init__(self, lora_model_path: str):
        self.lora_model_path = lora_model_path
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.model = None
        
    def load_fixed_model(self):
        """åŠ è½½ä¿®å¤ç‰ˆæœ¬çš„æ¨¡å‹"""
        # ç›´æ¥å¯¼å…¥ä¿®å¤ç‰ˆæœ¬çš„å‡½æ•°
        # from lora.stable_sam_lora_wrapper import load_fixed_sam_lora_model
        from lora.stable_sam_lora_wrapper import load_stable_sam_lora_model as load_sam_lora_model
        
        print("æ­£åœ¨åŠ è½½ä¿®å¤ç‰ˆæœ¬çš„LoRAæ¨¡å‹...")
        self.model = load_sam_lora_model("vit_b_lm", self.lora_model_path, str(self.device))
        
        if self.model is None:
            print("âŒ ä¿®å¤ç‰ˆæœ¬æ¨¡å‹åŠ è½½å¤±è´¥")
            return False
        
        self.model = self.model.to(self.device)
        self.model.eval()
        print(f"âœ… ä¿®å¤ç‰ˆæœ¬æ¨¡å‹åŠ è½½æˆåŠŸï¼Œè®¾å¤‡: {self.device}")
        return True
    
    def test_batch_sizes(self, batch_sizes: list = [1, 2, 4, 8, 16]):
        """æµ‹è¯•ä¸åŒçš„æ‰¹æ¬¡å¤§å°"""
        if not self.load_fixed_model():
            return
        
        print(f"\n{'='*80}")
        print("ğŸ§ª æµ‹è¯•ä¿®å¤ç‰ˆæœ¬çš„æ‰¹é‡æ¨ç†")
        print(f"{'='*80}")
        
        results = {}
        
        for batch_size in batch_sizes:
            print(f"\nğŸ“Š æµ‹è¯• Batch Size = {batch_size}")
            print("-" * 50)
            
            try:
                # åˆ›å»ºæµ‹è¯•æ•°æ®
                test_images = torch.randn(batch_size, 3, 1024, 1024, device=self.device)
                
                # å‡†å¤‡è¾“å…¥
                batch_inputs = {
                    'images': test_images,
                    'point_coords': [],
                    'point_labels': [],
                    'boxes': [],
                    'mask_inputs': None,
                    'multimask_output': False
                }
                
                # æµ‹è¯•æ¨ç†
                start_time = time.time()
                
                with torch.no_grad():
                    outputs = self.model(batch_inputs)
                
                inference_time = time.time() - start_time
                
                # éªŒè¯è¾“å‡º
                masks = outputs['masks']
                iou_predictions = outputs['iou_predictions']
                
                print(f"   âœ… æ¨ç†æˆåŠŸ!")
                print(f"   ğŸ“ è¾“å‡ºå½¢çŠ¶:")
                print(f"      æ©ç : {masks.shape}")
                print(f"      IoUé¢„æµ‹: {iou_predictions.shape}")
                print(f"   â±ï¸  æ¨ç†æ—¶é—´: {inference_time:.4f}s")
                print(f"   ğŸ“ˆ å¹³å‡æ—¶é—´/å›¾åƒ: {inference_time/batch_size:.4f}s")
                
                # éªŒè¯è¾“å‡ºçš„åˆç†æ€§
                validation_result = self._validate_outputs(masks, iou_predictions, batch_size)
                if validation_result['valid']:
                    print(f"   âœ… è¾“å‡ºéªŒè¯é€šè¿‡")
                else:
                    print(f"   âš ï¸  è¾“å‡ºéªŒè¯è­¦å‘Š: {validation_result['warnings']}")
                
                # ä¿å­˜ç»“æœ
                results[batch_size] = {
                    'success': True,
                    'inference_time': inference_time,
                    'time_per_image': inference_time / batch_size,
                    'output_shapes': {
                        'masks': list(masks.shape),
                        'iou_predictions': list(iou_predictions.shape)
                    },
                    'validation': validation_result
                }
                
            except Exception as e:
                print(f"   âŒ æ¨ç†å¤±è´¥: {e}")
                results[batch_size] = {
                    'success': False,
                    'error': str(e)
                }
        
        # æ‰“å°æ€»ç»“
        self._print_test_summary(results)
        return results
    
    def _validate_outputs(self, masks: torch.Tensor, iou_predictions: torch.Tensor, batch_size: int) -> dict:
        """éªŒè¯è¾“å‡ºçš„åˆç†æ€§"""
        validation = {'valid': True, 'warnings': []}
        
        # æ£€æŸ¥å½¢çŠ¶
        expected_mask_shape = (batch_size, 1, 256, 256)
        expected_iou_shape = (batch_size, 1)
        
        if masks.shape != expected_mask_shape:
            validation['warnings'].append(f"æ©ç å½¢çŠ¶å¼‚å¸¸: æœŸæœ›{expected_mask_shape}, å®é™…{masks.shape}")
        
        if iou_predictions.shape != expected_iou_shape:
            validation['warnings'].append(f"IoUå½¢çŠ¶å¼‚å¸¸: æœŸæœ›{expected_iou_shape}, å®é™…{iou_predictions.shape}")
        
        # æ£€æŸ¥æ•°å€¼èŒƒå›´
        mask_min, mask_max = masks.min().item(), masks.max().item()
        iou_min, iou_max = iou_predictions.min().item(), iou_predictions.max().item()
        
        if mask_min < -10 or mask_max > 10:
            validation['warnings'].append(f"æ©ç æ•°å€¼èŒƒå›´å¼‚å¸¸: [{mask_min:.3f}, {mask_max:.3f}]")
        
        if iou_min < 0 or iou_max > 1:
            validation['warnings'].append(f"IoUæ•°å€¼èŒƒå›´å¼‚å¸¸: [{iou_min:.3f}, {iou_max:.3f}]")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰NaNæˆ–Inf
        if torch.isnan(masks).any():
            validation['warnings'].append("æ©ç åŒ…å«NaNå€¼")
        
        if torch.isinf(masks).any():
            validation['warnings'].append("æ©ç åŒ…å«Infå€¼")
        
        if torch.isnan(iou_predictions).any():
            validation['warnings'].append("IoUé¢„æµ‹åŒ…å«NaNå€¼")
        
        if validation['warnings']:
            validation['valid'] = False
        
        return validation
    
    def _print_test_summary(self, results: dict):
        """æ‰“å°æµ‹è¯•æ€»ç»“"""
        print(f"\n{'='*80}")
        print("ğŸ“‹ æ‰¹é‡æ¨ç†æµ‹è¯•æ€»ç»“")
        print(f"{'='*80}")
        
        successful_batches = [bs for bs, result in results.items() if result['success']]
        failed_batches = [bs for bs, result in results.items() if not result['success']]
        
        print(f"âœ… æˆåŠŸçš„æ‰¹æ¬¡å¤§å°: {successful_batches}")
        if failed_batches:
            print(f"âŒ å¤±è´¥çš„æ‰¹æ¬¡å¤§å°: {failed_batches}")
        
        if successful_batches:
            print(f"\nğŸ“Š æ€§èƒ½ç»Ÿè®¡:")
            print(f"{'æ‰¹æ¬¡å¤§å°':<8} {'æ€»æ—¶é—´(s)':<12} {'å¹³å‡æ—¶é—´/å›¾åƒ(s)':<18} {'ååé‡(å›¾åƒ/s)':<15}")
            print("-" * 60)
            
            for batch_size in successful_batches:
                result = results[batch_size]
                total_time = result['inference_time']
                time_per_image = result['time_per_image']
                throughput = 1.0 / time_per_image
                
                print(f"{batch_size:<8} {total_time:<12.4f} {time_per_image:<18.4f} {throughput:<15.2f}")
        
        print(f"\nğŸ¯ ç»“è®º:")
        if len(successful_batches) == len(results):
            print("   âœ… æ‰€æœ‰æ‰¹æ¬¡å¤§å°éƒ½æˆåŠŸï¼æ‰¹é‡æ¨ç†ä¿®å¤æˆåŠŸï¼")
        elif successful_batches:
            max_successful = max(successful_batches)
            print(f"   âš ï¸  éƒ¨åˆ†æˆåŠŸï¼Œæœ€å¤§æ”¯æŒæ‰¹æ¬¡å¤§å°: {max_successful}")
        else:
            print("   âŒ æ‰€æœ‰æ‰¹æ¬¡éƒ½å¤±è´¥ï¼Œéœ€è¦è¿›ä¸€æ­¥è°ƒè¯•")
    
    def benchmark_performance(self, batch_size: int = 8, num_iterations: int = 10):
        """æ€§èƒ½åŸºå‡†æµ‹è¯•"""
        if not self.model:
            if not self.load_fixed_model():
                return
        
        print(f"\nğŸƒâ€â™‚ï¸ æ€§èƒ½åŸºå‡†æµ‹è¯• (æ‰¹æ¬¡å¤§å°: {batch_size}, è¿­ä»£æ¬¡æ•°: {num_iterations})")
        print("-" * 60)
        
        # é¢„çƒ­
        print("é¢„çƒ­ä¸­...")
        for _ in range(3):
            test_images = torch.randn(batch_size, 3, 1024, 1024, device=self.device)
            batch_inputs = {
                'images': test_images,
                'point_coords': [],
                'point_labels': [],
                'boxes': [],
                'mask_inputs': None,
                'multimask_output': False
            }
            
            with torch.no_grad():
                _ = self.model(batch_inputs)
        
        # æ­£å¼æµ‹è¯•
        print("å¼€å§‹åŸºå‡†æµ‹è¯•...")
        times = []
        
        for i in tqdm(range(num_iterations), desc="åŸºå‡†æµ‹è¯•"):
            test_images = torch.randn(batch_size, 3, 1024, 1024, device=self.device)
            batch_inputs = {
                'images': test_images,
                'point_coords': [],
                'point_labels': [],
                'boxes': [],
                'mask_inputs': None,
                'multimask_output': False
            }
            
            torch.cuda.synchronize() if self.device.type == 'cuda' else None
            start_time = time.time()
            
            with torch.no_grad():
                outputs = self.model(batch_inputs)
            
            torch.cuda.synchronize() if self.device.type == 'cuda' else None
            end_time = time.time()
            
            times.append(end_time - start_time)
        
        # ç»Ÿè®¡ç»“æœ
        times = np.array(times)
        mean_time = times.mean()
        std_time = times.std()
        min_time = times.min()
        max_time = times.max()
        
        time_per_image = mean_time / batch_size
        throughput = batch_size / mean_time
        
        print(f"\nğŸ“Š åŸºå‡†æµ‹è¯•ç»“æœ:")
        print(f"   å¹³å‡æ¨ç†æ—¶é—´: {mean_time:.4f}s Â± {std_time:.4f}s")
        print(f"   æœ€å¿«æ¨ç†æ—¶é—´: {min_time:.4f}s")
        print(f"   æœ€æ…¢æ¨ç†æ—¶é—´: {max_time:.4f}s")
        print(f"   å¹³å‡æ—¶é—´/å›¾åƒ: {time_per_image:.4f}s")
        print(f"   ååé‡: {throughput:.2f} å›¾åƒ/ç§’")
        
        return {
            'mean_time': mean_time,
            'std_time': std_time,
            'min_time': min_time,
            'max_time': max_time,
            'time_per_image': time_per_image,
            'throughput': throughput
        }
    
    def test_with_real_data(self, data_samples: list):
        """ä½¿ç”¨çœŸå®æ•°æ®æµ‹è¯•"""
        if not self.model:
            if not self.load_fixed_model():
                return
        
        print(f"\nğŸ–¼ï¸  çœŸå®æ•°æ®æµ‹è¯• ({len(data_samples)} ä¸ªæ ·æœ¬)")
        print("-" * 50)
        
        try:
            # å‡†å¤‡çœŸå®æ•°æ®æ‰¹æ¬¡
            images_list = []
            for sample in data_samples:
                # å‡è®¾sampleæ˜¯å›¾åƒè·¯å¾„æˆ–å·²åŠ è½½çš„å›¾åƒ
                if isinstance(sample, str):
                    # åŠ è½½å›¾åƒçš„é€»è¾‘
                    from utils.file_utils import load_image
                    image = load_image(sample, convert_to_grayscale=False)
                    if image is not None:
                        images_list.append(torch.from_numpy(image).permute(2, 0, 1).float() / 255.0)
                elif isinstance(sample, torch.Tensor):
                    images_list.append(sample)
            
            if not images_list:
                print("   âŒ æ²¡æœ‰æœ‰æ•ˆçš„å›¾åƒæ•°æ®")
                return
            
            # è°ƒæ•´åˆ°ç»Ÿä¸€å°ºå¯¸å¹¶åˆ›å»ºæ‰¹æ¬¡
            processed_images = []
            for img in images_list:
                if img.shape[-2:] != (1024, 1024):
                    img = torch.nn.functional.interpolate(
                        img.unsqueeze(0), size=(1024, 1024), mode='bilinear', align_corners=False
                    ).squeeze(0)
                processed_images.append(img)
            
            # åˆ›å»ºæ‰¹æ¬¡å¼ é‡
            batch_images = torch.stack(processed_images).to(self.device)
            
            batch_inputs = {
                'images': batch_images,
                'point_coords': [],
                'point_labels': [],
                'boxes': [],
                'mask_inputs': None,
                'multimask_output': False
            }
            
            # æ¨ç†
            start_time = time.time()
            with torch.no_grad():
                outputs = self.model(batch_inputs)
            inference_time = time.time() - start_time
            
            print(f"   âœ… çœŸå®æ•°æ®æ¨ç†æˆåŠŸ!")
            print(f"   ğŸ“ è¾“å‡ºå½¢çŠ¶: æ©ç {outputs['masks'].shape}, IoU{outputs['iou_predictions'].shape}")
            print(f"   â±ï¸  æ¨ç†æ—¶é—´: {inference_time:.4f}s")
            print(f"   ğŸ“ˆ å¹³å‡æ—¶é—´/å›¾åƒ: {inference_time/len(data_samples):.4f}s")
            
            return outputs
            
        except Exception as e:
            print(f"   âŒ çœŸå®æ•°æ®æµ‹è¯•å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    # é…ç½®è·¯å¾„
    lora_model_path = "/LD-FS/home/zhenhuachen/code/github/DeepMicroSeg/data/lora_model/lora_model_293t_train0_val10_test90/lora_finetune_vit_b_lm_r8/final_model"
    
    print("ğŸš€ å¼€å§‹æµ‹è¯•ä¿®å¤ç‰ˆæœ¬çš„æ‰¹é‡æ¨ç†")
    print(f"æ¨¡å‹è·¯å¾„: {lora_model_path}")
    
    # åˆ›å»ºæµ‹è¯•å®ä¾‹
    tester = FixedBatchInferenceTest(lora_model_path)
    
    # æµ‹è¯•1: ä¸åŒæ‰¹æ¬¡å¤§å°
    print("\n" + "="*80)
    print("æµ‹è¯•1: ä¸åŒæ‰¹æ¬¡å¤§å°çš„æ¨ç†èƒ½åŠ›")
    print("="*80)
    batch_results = tester.test_batch_sizes([1, 2, 4, 8, 16, 32])
    
    # æµ‹è¯•2: æ€§èƒ½åŸºå‡†æµ‹è¯•
    if batch_results and any(r['success'] for r in batch_results.values()):
        print("\n" + "="*80)
        print("æµ‹è¯•2: æ€§èƒ½åŸºå‡†æµ‹è¯•")
        print("="*80)
        
        # æ‰¾åˆ°æœ€å¤§æˆåŠŸçš„æ‰¹æ¬¡å¤§å°è¿›è¡ŒåŸºå‡†æµ‹è¯•
        successful_batches = [bs for bs, result in batch_results.items() if result['success']]
        if successful_batches:
            optimal_batch_size = min(8, max(successful_batches))  # æœ€å¤§8ï¼Œæˆ–è€…æœ€å¤§æˆåŠŸæ‰¹æ¬¡
            tester.benchmark_performance(batch_size=optimal_batch_size, num_iterations=20)
    
    print(f"\n{'='*80}")
    print("ğŸ‰ ä¿®å¤ç‰ˆæœ¬æ‰¹é‡æ¨ç†æµ‹è¯•å®Œæˆ!")
    print(f"{'='*80}")


if __name__ == "__main__":
    main()